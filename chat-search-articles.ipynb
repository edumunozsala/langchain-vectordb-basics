{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Chatbot to search Articles using Google Search\n",
    "## Introduction\n",
    "\n",
    "While the Large Language Models (LLMs) possess impressive capabilities, they have certain limitations that can present challenges when deploying them in a production environment. The hallucination problem makes them answer certain questions wrongly with high confidence. This issue can be attributed to various factors, one of which is that their training process has a cut-off date. So, these models do not have access to events preceding that date.\n",
    "\n",
    "A workaround approach is to present the required information to the model and leverage its reasoning capability to find/extract the answer. Furthermore, it is possible to present the top-matched results a search engine returns as the context for a user’s query.\n",
    "\n",
    "This lesson will explore the idea of finding the best articles from the Internet as the context for a chatbot to find the correct answer. We will use LangChain’s integration with Google Search API and the Newspaper library to extract the stories from search results. This is followed by choosing and using the most relevant options in the prompt.\n",
    "\n",
    "The user query is used to extract relevant articles using a search engine (e.g. Bing or Google Search), which are then split into chunks. We then compute the embeddings of each chunk, rank them by cosine similarity with respect to the embedding of the query, and put the most relevant chunks into a prompt to generate the final answer, while also keeping track of the sources.\n",
    "\n",
    "Ask Trending Questions\n",
    "Let’s start this lesson by seeing an example. The following piece must be familiar by now. It uses the OpenAI GPT-3.5-turbo model to create an assistant to answer questions. We will ask the model to name the latest Fast & Furious movie, released recently. Therefore, the model couldn’t have seen the answer during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe latest Fast and Furious movie is Fast & Furious 9, which was released in May 2021.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"You are an assistant that answers the following question correctly and honestly: {question}\\n\\n\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "\n",
    "question_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "question_chain.run(\"what is the latest fast and furious movie?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Search Results\n",
    "\n",
    "This section uses LangChain’s GoogleSearchAPIWrapper class to receive search results. It works in combination with the Tool class that presents the utilities for agents to help them interact with the outside world. In this case, creating a tool out of any function, like top_n_results is possible. The API will return the page’s title, URL, and a short description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast & Furious movies in order | chronological and release order ...\n",
      "https://www.radiotimes.com/movies/fast-and-furious-order/\n",
      "Mar 22, 2023 ... Fast & Furious Presents: Hobbs & Shaw (2019); F9 (2021); Fast and Furious 10 (2023). Tokyo Drift also marks the first appearance of Han Lue, a ...\n",
      "--------------------------------------------------\n",
      "FAST X | Official Trailer 2 - YouTube\n",
      "https://www.youtube.com/watch?v=aOb15GVFZxU\n",
      "Apr 19, 2023 ... FAST X | Official Trailer 2 · Comments10K.\n",
      "--------------------------------------------------\n",
      "Fast & Furious - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Fast_%26_Furious\n",
      "Fast X was designed to be the final movie of the franchise which later evolved in becoming a two part finale. Justin Lin was brought back to direct both movies ...\n",
      "--------------------------------------------------\n",
      "Here's How to Watch Every Fast and Furious Movie In Order ...\n",
      "https://www.menshealth.com/entertainment/a36716650/fast-and-furious-movies-in-order/\n",
      "Sep 18, 2023 ... Furious 7 is the last movie in the Fast and Furious series to feature the late Paul Walker (as Brian O'Conner), and the movie sends his ...\n",
      "--------------------------------------------------\n",
      "How to Watch Fast and Furious Movies in Chronological Order - IGN\n",
      "https://www.ign.com/articles/fast-and-furious-movies-in-order\n",
      "Sep 17, 2023 ... F9 (2021) ... The series' most recent film before Fast X, once again directed by Justin Lin, pits Dom and the crew against Jakob Toretto, Dom's ...\n",
      "--------------------------------------------------\n",
      "All 11 'Fast and Furious' Movies, Ranked from Best to Worst\n",
      "https://www.menshealth.com/entertainment/g28645511/fast-and-furious-movies-ranked/\n",
      "Sep 18, 2023 ... I Watched All 22 Hours and 56 Minutes of Fast and Furious Movies To Bring You This Ranking · 11. The Fate of the Furious (2017) · 10. 2 Fast 2 ...\n",
      "--------------------------------------------------\n",
      "How many 'Fast & Furious' movies are there? Here's the list in order.\n",
      "https://www.usatoday.com/story/entertainment/movies/2022/07/29/fast-and-furious-movies-order-of-release/10062943002/\n",
      "Jul 29, 2022 ... What is the correct order of 'Fast and Furious' movies? · \"The Fast and the Furious\" (2001) · \"2 Fast 2 Furious\" (2003) · \"Fast & Furious\" (2009) ...\n",
      "--------------------------------------------------\n",
      "Fast & Furious Movies In Order: How to Watch Fast Saga ...\n",
      "https://editorial.rottentomatoes.com/guide/fast-furious-movies-in-order/\n",
      "After that, hop to franchise best Furious 7. Follow it up with The Fate of the Furious and spin-off Hobbs & Shaw and then the latest: F9 and Fast X. See below ...\n",
      "--------------------------------------------------\n",
      "Is Fast X the Last Movie of the Fast and Furious Franchise?\n",
      "https://www.comingsoon.net/guides/news/1287501-is-fast-x-the-last-movie-fast-and-furious-franchise-final-one-10\n",
      "May 11, 2023 ... Will there be another Fast and Furious movie? ... Fast X isn't the last movie of the Fast and Furious franchise, as Fast and Furious 11 is already ...\n",
      "--------------------------------------------------\n",
      "Furious Six was the last good Fast and Furious. : r/movies\n",
      "https://www.reddit.com/r/movies/comments/kkmvi3/furious_six_was_the_last_good_fast_and_furious/\n",
      "Dec 26, 2020 ... Furious Six was the last good Fast and Furious. ... I know a lot of people hate pretty much every film in the franchise that isn't the original ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULTS = 10\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULTS)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top_n_results\n",
    ")\n",
    "\n",
    "query = \"What is the latest fast and furious movie?\"\n",
    "\n",
    "results = tool.run(query)\n",
    "\n",
    "for result in results:\n",
    "    print(result[\"title\"])\n",
    "    print(result[\"link\"])\n",
    "    print(result[\"snippet\"])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the results variable’s link key to download and parse the contents. The newspaper library takes care of everything. However, it might be unable to capture some contents in certain situations, like anti-bot mechanisms or having a file as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "\n",
    "pages_content = []\n",
    "\n",
    "for result in results:\n",
    "\ttry:\n",
    "\t\tarticle = newspaper.Article(result[\"link\"])\n",
    "\t\tarticle.download()\n",
    "\t\tarticle.parse()\n",
    "\t\tif len(article.text) > 0:\n",
    "\t\t\tpages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
    "\texcept:\n",
    "\t\tcontinue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Search Results\n",
    "\n",
    "We now have the top 10 results from the Google search. (Honestly, who looks at Google’s second page?) However, it is not efficient to pass all the contents to the model because of the following reasons:\n",
    "\n",
    "The model’s context length is limited.\n",
    "It will significantly increase the cost if we process all the search results.\n",
    "In almost all cases, they share similar pieces of information.\n",
    "So, let’s find the most relevant results, \n",
    "\n",
    "Incorporating the LLMs embedding generation capability will enable us to find contextually similar content. It means converting the text to a high-dimensionality tensor that captures meaning. The cosine similarity function can find the closest article with respect to the user’s question.\n",
    "\n",
    "It starts by splitting the texts using the RecursiveCharacterTextSplitter class to ensure the content lengths are inside the model’s input length. The Document class will create a data structure from each chunk that enables saving metadata like URL as the source. The model can later use this data to know the content’s location.\n",
    "\n",
    "The subsequent step involves utilizing the OpenAI API's OpenAIEmbeddings class, specifically the .embed_documents() method for search results and the .embed_query() method for the user's question, to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "for d in pages_content:\n",
    "\tchunks = text_splitter.split_text(d[\"text\"])\n",
    "\tfor chunk in chunks:\n",
    "\t\tnew_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
    "\t\tdocs.append(new_doc)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the get_top_k_indices function accepts the content and query embedding vectors and returns the index of top K candidates with the highest cosine similarities to the user's request. Later, we use the indexes to retrieve the best-fit documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "  # convert the lists of vectors to numpy arrays\n",
    "  list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "  query_vector = np.array(query_vector)\n",
    "\n",
    "  # compute cosine similarities\n",
    "  similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "  # sort the vectors based on cosine similarity\n",
    "  sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "  # retrieve the top K indices from the sorted list\n",
    "  top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "  return top_k_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 2\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain with Source\n",
    "\n",
    "Finally, we used the selected articles in our prompt (using the stuff method) to assist the model in finding the correct answer. LangChain provides the load_qa_with_sources_chain() chain, which is designed to accept a list of input_documents as a source of information and a question argument which is the user’s question. The final part involves preprocessing the model’s response to extract its answer and the sources it utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The latest Fast and Furious movie is Fast and Furious Presents: Hobbs & Shaw (2019).\n",
      "Sources: https://en.wikipedia.org/wiki/Fast_%26_Furious, https://www.menshealth.com/entertainment/a36716650/fast-and-furious-movies-in-order/\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "\n",
    "response = chain({\"input_documents\": best_k_documents, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "response_text, response_sources = response[\"output_text\"].split(\"SOURCES:\")\n",
    "response_text = response_text.strip()\n",
    "response_sources = response_sources.strip()\n",
    "\n",
    "print(f\"Answer: {response_text}\")\n",
    "print(f\"Sources: {response_sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
