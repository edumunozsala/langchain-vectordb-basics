{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents: Content Generators and Reasoning Engines\n",
    "## Introduction\n",
    "In the fascinating world of artificial intelligence, LangChain and LLMs have opened up new horizons in data analysis, information synthesis, and content generation. Central to their functionality is the concept of Agents - intelligent systems that utilize LLMs to determine actions and facilitate complex tasks. In this way, LLMs are used more as a reasoning engine or a planner and less as content generators per-se. We discuss two primary ways we can harness the capabilities of LMMs: as content generators and as reasoning engines.\n",
    "\n",
    "LLMs leverage their internal knowledge as content generators to create engaging and creative content from scratch. On the other hand, used as reasoning engines, they act as proficient synthesizers of information, extracting and summarizing relevant data from a multitude of sources and planning the next actions to take. Both these approaches have distinct advantages and challenges, with the choice largely dependent on the specific requirements of the task.\n",
    "\n",
    "### Agents\n",
    "In the context of language models, agents are used to decide the course of action and the sequence of these actions. These actions can either be the utilization of a tool, observing its output, or offering a response to the user. The real potential of agents unfolds when they are utilized appropriately. This explanation aims to simplify the usage of agents via the highest-level API.\n",
    "\n",
    "Before diving into the practical usage, it's crucial to understand the following terms:\n",
    "\n",
    "- Tool: A function that performs a specific task. It can be a Google Search, a Database lookup, a Python REPL, or other chains. A tool's interface is typically a function that takes a string as an input and returns a string as an output.\n",
    "- Language Learning Model: The language model that powers the agent.\n",
    "- Agent: The agent to use, identified by a string that references a supported agent class. It’s what orchestrates the LLM and the tools. This explanation focuses on using the standard supported agents via the highest-level API. For custom agent implementation, refer to the appropriate documentation.\n",
    "\n",
    "Agents in LangChain play a crucial role in the decision-making and execution of tasks based on user input. They evaluate the situation and decide on the appropriate tools to use, if necessary.\n",
    "\n",
    "Presently, most of the agents in LangChain fall into one of these two categories:\n",
    "\n",
    "- \"Action Agents\": These agents determine and execute a single action. They are typically used for straightforward tasks.\n",
    "- \"Plan-and-Execute Agents\": These agents first devise a plan comprising multiple actions and then execute each action sequentially. They are more suited for complex or long-running tasks as they help maintain focus on long-term objectives.\n",
    "\n",
    "While Action Agents are more traditional and suitable for smaller tasks, Plan-and-Execute Agents help maintain long-term objectives and focus. However, they might lead to more calls and higher latency. Often, it's beneficial to let an Action Agent manage the execution for the Plan-and-Execute agent, thus utilizing both strengths.\n",
    "\n",
    "For example, a high-level workflow of Action Agents would look something like this:\n",
    "\n",
    "- The agent receives user input.\n",
    "- It decides which tool to use (if any) and determines its input.\n",
    "- The chosen tool is called with the provided input, and an observation (the output of the tool) is recorded.\n",
    "- The history of the tool, tool input, and observation are relayed back to the agent, which then decides the next step.\n",
    "- This process is repeated until the agent no longer needs to use a tool, at which point it directly responds to the user.\n",
    "\n",
    "The most critical abstraction to understand is the agent itself. In the context of LangChain, the term \"agents\" pertains to the concept of employing a language model as a reasoning mechanism and linking it with the key element - a tool.\n",
    "\n",
    "Tools are instrumental in connecting the language model with other sources of data or computation, including search engines, APIs, and other data repositories. Language models can only access the knowledge they've been trained on, which can quickly become obsolete. Therefore, tools are essential as they allow the agent to retrieve and incorporate current data into the prompt as context. Tools can also execute actions (like running code or modifying files) and observe the results, subsequently informing the language model's decision-making process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Questions using an LLM as a reasoning engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the number of goals scored in the 2018 soccer world cup\n",
      "Action: Google Search\n",
      "Action Input: \"number of goals scored in 2018 soccer world cup\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSep 22, 2023 ... This was three more goals than the previous tournament in 2018. Goals galore. The highest ever goals to game ratio was set during the 1954 World ... Jan 31, 2020 ... A total of 169 goals were scored at the group and knockout stages of the FIFA World Cup held in Russia from the 14th of June to the 15th of July ... Aug 28, 2023 ... This number can be attributed to some unusually high-scoring games, which included Austria 7 Switzerland 5 and Hungary 9 South Korea 0. The ... Number of goals scored in the matches played between the teams in question;; Fair play points in all group matches (only one deduction could be applied to a ... France. Winner. 7. Matches played. 14. Goals. 1.7. Goal Average. 12. Yellow Cards. 0. Red Cards. TOURNAMENT AWARDS. Previous. Best Young Player Award. Kylian ... Question: The total number of goals scored in each of the 64 matches of the 2018 Soccer World Cup that was held in Russia is provided in the table below Let ... 0 · Luka MODRIC · Players · Top Scorers. The aim of this study was to elucidate pattern of attacking actions leading up to goal scoring during the 14 FIFA World Cups from 1966 to 2018. Top Scorers ; Sergio AGUERO. 2 · Sergio ; Lionel MESSI. 1 · Lionel ; Faustino Marcos Alberto Rojo. 1 · Faustino. Nov 20, 2022 ... If two teams share the same number of points and goal differential, the next criteria to determine ranking is number of goals scored in all ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1000 + 169 = 1169\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1000 + 169 = 1169\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "#os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR-GOOGLE-SEARCH-API-KEY>\"\n",
    "#os.environ[\"GOOGLE_CSE_ID\"] = \"<YOUR-CUSTOM-SEARCH-ENGINE-ID>\"\n",
    "\n",
    "# Importing necessary modules\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Loading the language model to control the agent\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Loading some tools to use. The llm-math tool uses an LLM, so we pass that in.\n",
    "tools = load_tools([\"google-search\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Initializing an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Testing the agent\n",
    "query = \"What's the result of 1000 plus the number of goals scored in the soccer world cup in 2018?\"\n",
    "response = agent.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 169 goals scored in the soccer world cup in 2018, so the final answer is correct.\n",
    "\n",
    "In the example, the agent leverages its \"reasoning engine\" capabilities to generate responses. Instead of creating new content (acting as a content generator), the agent uses the tools at its disposal to gather, process, and synthesize information. The entire output was truncated, and the agent skillfully employed the LLM-math tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent as a new Content Creator\n",
    "\n",
    "The agent would create new content as a content generator rather than just pulling and processing existing information. Let's imagine a scenario where we want the agent to write a short science fiction story based on a given prompt.\n",
    "\n",
    "We could initialize the agent with a language model and set its temperature parameter to a higher value to encourage more creativity in its outputs. It is not required to use external tools, as the agent generates content rather than retrieving or processing it.\n",
    "\n",
    "The language model will generate a long science fiction story about interstellar explorers based on the patterns it learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a tool to help me generate a story\n",
      "Action: Science Fiction Writer\n",
      "Action Input: Generate a story about interstellar explorers\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m.\n",
      "\n",
      "The year was 2120 and the human race had finally achieved interstellar travel. After decades of research and development, a team of brave explorers had been assembled to embark on a mission to explore the unknown reaches of the universe.\n",
      "\n",
      "The team was led by Captain John Smith, a veteran of many space missions. He was joined by a diverse group of scientists, engineers, and adventurers, all eager to explore the unknown.\n",
      "\n",
      "The team's first destination was a distant star system known as Alpha Centauri. After months of travel, they arrived at the system and began to explore the planets and moons in the vicinity.\n",
      "\n",
      "The team discovered a number of strange and fascinating phenomena, from strange alien life forms to mysterious energy fields. They also encountered a number of hostile forces, from hostile aliens to powerful robotic forces.\n",
      "\n",
      "The team eventually made it back to Earth with a wealth of knowledge and data about the universe. They had made a number of important discoveries, and their mission had been a success.\n",
      "\n",
      "The interstellar explorers had opened up a new era of exploration and discovery, and the human race was now ready to explore the stars.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The interstellar explorers had opened up a new era of exploration and discovery, and the human race was now ready to explore the stars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The interstellar explorers had opened up a new era of exploration and discovery, and the human race was now ready to explore the stars.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"You're a renowned science fiction writer. {query}\"\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Science Fiction Writer',\n",
    "        func=llm_chain.run,\n",
    "        description='Use this tool for generating science fiction stories. Input should be a command about generating specific types of stories.'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initializing an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Testing the agent with the new prompt\n",
    "response = agent.run(\"Compose an epic science fiction saga about interstellar explorers\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Agent is primarily using its internal knowledge to generate the output. Here's a brief explanation of how that works:\n",
    "\n",
    "The agent receives a prompt to \"Compose an epic science fiction saga about interstellar explorers.”\n",
    "The agent then uses its understanding of language, narrative structure, and the specific themes mentioned in the prompt (science fiction, interstellar exploration, etc.) to generate a story.\n",
    "LLM's understanding comes from its training data. It was trained on a diverse range of internet text, so it has a broad base of information to draw from. When asked to generate a science fiction story, it uses patterns it learned during training about how such stories are typically structured and what elements they usually contain.\n",
    "\n",
    "Remember, even though the language model has vast training data to draw from, it doesn't \"know\" specific facts or have access to real-time information. Its responses are generated based on patterns learned during training, not from a specific knowledge database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Code Example of Using BabyAGI\n",
    "\n",
    "Although BabyAGI uses specific vector stores and model providers, one of the benefits of implementing it with LangChain is that you can easily swap those out for different options. In this implementation, we use a FAISS vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "\n",
    "# Define the embedding model\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Initialize the vectorstore\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a call to BabyAGI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "1. Research the best time to visit the Grand Canyon\n",
      "2. Book flights to the Grand Canyon\n",
      "3. Book a hotel near the Grand Canyon\n",
      "4. Research the best activities to do at the Grand Canyon\n",
      "5. Research the best restaurants near the Grand Canyon\n",
      "6. Pack necessary items for the trip\n",
      "7. Make a budget for the trip\n",
      "8. Make a list of places to visit at the Grand Canyon\n",
      "9. Make a list of souvenirs to buy\n",
      "10. Make a list of photos to take\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research the best places to view the Grand Canyon\n",
      "3: Research the best places to take photos at the Grand Canyon\n",
      "4: Research the best places to take a tour at the Grand Canyon\n",
      "5: Research the best places to take a helicopter tour at the Grand Canyon\n",
      "6: Research the best places to hike at the Grand Canyon\n",
      "7: Research the best places to camp at the Grand Canyon\n",
      "8: Research the best places to buy souvenirs at the Grand Canyon\n",
      "9: Research the cost of activities at the Grand Canyon\n",
      "10: Research the cost of restaurants near the Grand Canyon\n",
      "11: Research the best transportation options to get to the Grand Canyon\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research the best places to view the Grand Canyon\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research the best places to view the Grand Canyon. I will look into the various viewpoints, trails, and activities available at the Grand Canyon. I will also research the best times of year to visit the Grand Canyon, as well as the best ways to get there. I will compile my findings into a list of the best places to view the Grand Canyon, which can be added to the todo list.\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research the best places to take photos at the Grand Canyon,\n",
      "4: Research the best places to take a tour at the Grand Canyon,\n",
      "5: Research the best places to take a helicopter tour at the Grand Canyon,\n",
      "6: Research the best places to hike at the Grand Canyon,\n",
      "7: Research the best places to camp at the Grand Canyon,\n",
      "8: Research the best places to buy souvenirs at the Grand Canyon,\n",
      "9: Research the cost of activities at the Grand Canyon,\n",
      "10: Research the cost of restaurants near the Grand Canyon,\n",
      "11: Research the best transportation options to get to the Grand Canyon,\n",
      "12: Research the best times of year to visit the Grand Canyon,\n",
      "13: Research the cost of lodging near the Grand Canyon,\n",
      "14: Research the best places to take a boat tour at the Grand Canyon,\n",
      "15: Research the best places to take a hot air balloon ride at the Grand Canyon,\n",
      "16: Research the best places to take a mule ride at the Grand Canyon,\n",
      "17: Research the best places to take a jeep tour at the Grand Canyon,\n",
      "18: Research the best places\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research the best places to take photos at the Grand Canyon,\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "To research the best places to take photos at the Grand Canyon, I would suggest looking into the various viewpoints and trails that offer the best views of the canyon. Additionally, I would recommend researching the best times of day to take photos, as the lighting can make a huge difference in the quality of the photos. Finally, I would suggest researching the best angles and perspectives to capture the most stunning photos of the Grand Canyon.\n",
      "\u001b[91m\u001b[1m\n",
      "*****TASK ENDING*****\n",
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.experimental import BabyAGI\n",
    "\n",
    "# set the goal\n",
    "goal = \"Plan a trip to the Grand Canyon\"\n",
    "\n",
    "# create thebabyagi agent\n",
    "# If max_iterations is None, the agent may go on forever if stuck in loops\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=OpenAI(model=\"text-davinci-003\", temperature=0),\n",
    "    vectorstore=vectorstore,\n",
    "    verbose=False,\n",
    "    max_iterations=3\n",
    ")\n",
    "response = baby_agi({\"objective\": goal})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.experimental import BabyAGI\n",
    "\n",
    "# set the goal\n",
    "goal = \"Plan a trip to the Grand Canyon\"\n",
    "\n",
    "# create thebabyagi agent\n",
    "# If max_iterations is None, the agent may go on forever if stuck in loops\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=OpenAI(model=\"text-davinci-003\", temperature=0),\n",
    "    vectorstore=vectorstore,\n",
    "    verbose=False,\n",
    "    max_iterations=3\n",
    ")\n",
    "response = baby_agi({\"objective\": goal})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
