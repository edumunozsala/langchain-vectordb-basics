{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain's Tool Utilization\n",
    "## Introduction\n",
    "\n",
    "Tools are modular, reusable components meticulously designed to accomplish specific tasks or provide answers to distinct types of questions. By integrating these tools seamlessly into the system, users can effortlessly tap into a diverse range of functionalities and information sources to tackle challenges and generate meaningful responses. In this lesson, we will explore the various Tools in LangChain, uncovering their unique capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Agents and Toolkits\n",
    "In LangChain, an Agent is a bot that acts using natural language instructions and can use tools to answer its queries. Based on user input, it is also used to determine which actions to take and in what order. An action can either be using a tool (such as a search engine or a calculator) and processing its output or returning a response to the user. Agents are powerful when used correctly, as they can dynamically call chains based on user input.\n",
    "\n",
    "An agent has access to a suite of tools and can decide which of these tools to call, depending on the user input. Tools are functions that perform specific duties. To create an agent in LangChain, you can use the initialize_agent function along with the load_tools function to prepare the tools the agent can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SERPAPI_API_KEY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edumu\\Google Drive\\Github\\langchain-vectordb-basics\\langchain-agents.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/langchain-agents.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/langchain-agents.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-davinci-003\u001b[39m\u001b[39m\"\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/langchain-agents.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tools \u001b[39m=\u001b[39m load_tools([\u001b[39m'\u001b[39m\u001b[39mserpapi\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrequests_all\u001b[39m\u001b[39m'\u001b[39m], llm\u001b[39m=\u001b[39mllm, serpapi_api_key\u001b[39m=\u001b[39mSERPAPI_API_KEY)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/langchain-agents.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m agent \u001b[39m=\u001b[39m initialize_agent(tools, llm, agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/langchain-agents.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m agent\u001b[39m.\u001b[39mrun(\u001b[39m\"\u001b[39m\u001b[39mtell me what is midjourney?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SERPAPI_API_KEY' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "tools = load_tools(['serpapi', 'requests_all'], llm=llm, serpapi_api_key=SERPAPI_API_KEY)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "agent.run(\"tell me what is midjourney?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google-Search\n",
    "\n",
    "LLMs inherently possess knowledge only up to the point at which they were trained, leaving them unaware of any information beyond that timeframe. Integrating search engines as tools within the LangChain system presents a significant advantage. The LangChain library provides a Google Search API wrapper that you can use within your project. You can use this wrapper as a standalone utility or as a tool within an agent.\n",
    "\n",
    "First, make sure you have an API Key and Custom Search Engine ID for the Google Search API. If you don’t already have a Custom Search Engine ID, the following tutorial is a helpful guide for generating one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Madrid, Spain - Image of the Week - Earth Watching',\n",
       "  'link': 'https://earth.esa.int/web/earth-watching/image-of-the-week/content/-/article/madrid-spain/',\n",
       "  'snippet': 'Madrid is the capital and largest city of Spain. The population of the city is roughly 3.3 million and the entire population of the Madrid metropolitan area\\xa0...'},\n",
       " {'title': 'Madrid | History, Population, Climate, & Facts | Britannica',\n",
       "  'link': 'https://www.britannica.com/place/Madrid',\n",
       "  'snippet': \"Madrid, city, capital of Spain and of Madrid provincia (province). Spain's arts and financial centre, the city proper and province form a comunidad autónoma\\xa0...\"},\n",
       " {'title': 'Madrid - Wikipedia',\n",
       "  'link': 'https://en.wikipedia.org/wiki/Madrid',\n",
       "  'snippet': 'Madrid is the capital and most populous city of Spain. The city has almost 3.4 million inhabitants and a metropolitan area population of approximately 6.7\\xa0...'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "#os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR-GOOGLE-API-KEY>\"\n",
    "#os.environ[\"GOOGLE_CSE_ID\"] = \"<YOUR-GOOGLE-CSE-ID>\"\n",
    "\n",
    "# As a standalone utility:\n",
    "from langchain. utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "search.results(\"What is the capital of Spain?\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the LangChain library, using the available tools requires some necessary steps to be taken. First, you need to initialize an agent, which is the central manager for effectively using these tools. Then, we need to define the language model that we want the agent to use. \n",
    "\n",
    "Now, we can initialize an agent and load the google-search tool for it to use. The agent will load the search results and provide them to the llm to answer our question. The ZERO_SHOT_REACT_DESCRIPTION type gives the freedom to choose any of the defined tools to provide context for the model based on their description. (You can use different agent types, read more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should research this online.\n",
      "Action: Google Search\n",
      "Action Input: National drink in Spain\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSangría is Spain's national drink, so of course it belongs on this list! Spain is famous for it's wine, which is the base of this drink. Lots of fresh fruit ... Although there is nothing officially considered the national alcoholic drink of Spain, many people would say is the Spanish sherry wine (also known as vino de ... Apr 20, 2021 ... Cava is the champagne of Spain and it comes in the form of a light, bubbly wine available in both white and rosé. Cava is often consumed ... \"Very Old Rare Sherry\", Pedro Ximenez by Garvey. Jerez de la Frontera (Andalusia, Spain), aged 30 years. Sherry is a national liquor of Spain. Nov 27, 2012 ... ... national drink (and that ampersands are expendable). From Cadiz in the south to San Sebastian in the north, the gin tonic is the undisputed ... Cava is Spain's version of Champagne. It's made in a very similar way, but with different grapes. Most cava grapes are grown in the Penedès region in Catalonia, ... Spain's national drink is sherry, a fortified wine made from white grapes grown in the Jerez region of Andalusia. Continue reading. Profile photo for Quora ... Even out of the country, people recognize the sherry wine as a very typical drink from Spain. Of course, when talking about the Spanish national drink, we could ... Gin Tonic – Spain's Obsession & National Drink · Little did we know, but our introduction to Spain's “national drink” began in 2012 at the home of Enrique Sr. Jul 10, 2022 ... But it couldn´t be another way, as wine is the national drink of Spain. ... If wine is the national drink of Spain, this is mostly due to its ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Sherry is the national drink of Spain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the national drink in Spain?', 'output': 'Sherry is the national drink of Spain.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, load_tools, AgentType\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "tools = load_tools([\"google-search\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "print( agent(\"What is the national drink in Spain?\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "\n",
    "The internet is an extensive source of information that Large Language Models cannot access directly. LangChain offers a convenient wrapper built around the Python Requests module to facilitate seamless interaction between LLMs and this wealth of information. This wrapper accepts a URL as an input and efficiently retrieves data from the specified URL, allowing LLMs to obtain and process web-based content effortlessly.\n",
    "\n",
    "In this example, we’ll set up a  fake RESTful backend using mockapi.io. To do it, follow these steps:\n",
    "\n",
    "- Go to mockapi.io and sign up for a free account.\n",
    "- After signing up, log in to your account.\n",
    "- Click on \"New Project\" (the \"+\" icon) and give your project a name. You don't need to fill in any optional fields.\n",
    "- Once the project is created, click on it to view your unique API endpoint.\n",
    "- Click on \"New Resource\" to create a new resource for your API. For example, if you want to create an endpoint for users, you can name the resource \"users.”\n",
    "- Define the schema for your resource. For instance, if you want each user to have an id, name, and email, you can use the following schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to get the list of users from the URL\n",
      "Action: requests_get\n",
      "Action Input: https://644696c1ee791e1e2903b0bb.mockapi.io/user\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{\"createdAt\":\"2023-04-24T07:55:47.634Z\",\"name\":\"Mr. Kelly Balistreri\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1244.jpg\",\"id\":\"1\"},{\"createdAt\":\"2023-04-24T03:54:44.108Z\",\"name\":\"Bradley Cronin\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/615.jpg\",\"id\":\"2\"},{\"createdAt\":\"2023-04-24T14:32:29.991Z\",\"name\":\"Jennifer Block Sr.\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/105.jpg\",\"id\":\"3\"},{\"createdAt\":\"2023-04-23T23:30:05.868Z\",\"name\":\"Nathaniel Toy V\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/533.jpg\",\"id\":\"4\"},{\"createdAt\":\"2023-04-24T03:01:15.797Z\",\"name\":\"Regina Veum\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1047.jpg\",\"id\":\"5\"},{\"createdAt\":\"2023-04-23T18:38:07.884Z\",\"name\":\"Miss Jaime Aufderhar\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/979.jpg\",\"id\":\"6\"},{\"createdAt\":\"2023-04-24T14:23:26.777Z\",\"name\":\"Ginger Rolfson I\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/311.jpg\",\"id\":\"7\"},{\"createdAt\":\"2023-04-24T02:10:57.769Z\",\"name\":\"Kelli Braun\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/24.jpg\",\"id\":\"8\"},{\"createdAt\":\"2023-04-24T14:31:17.436Z\",\"name\":\"Mrs. Ralph Bergstrom\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1219.jpg\",\"id\":\"9\"},{\"createdAt\":\"2023-04-23T16:19:28.348Z\",\"name\":\"Joshua Tromp IV\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1242.jpg\",\"id\":\"10\"},{\"createdAt\":\"2023-04-24T02:22:40.398Z\",\"name\":\"Mrs. Alexandra Lueilwitz\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/778.jpg\",\"id\":\"11\"},{\"createdAt\":\"2023-04-24T07:45:30.139Z\",\"name\":\"Reginald Parisian\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/634.jpg\",\"id\":\"12\"},{\"createdAt\":\"2023-04-24T07:54:38.530Z\",\"name\":\"Leon Hayes\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/846.jpg\",\"id\":\"13\"},{\"createdAt\":\"2023-04-23T21:42:33.334Z\",\"name\":\"Earl Runolfsson Jr.\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/919.jpg\",\"id\":\"14\"},{\"createdAt\":\"2023-04-23T16:24:07.464Z\",\"name\":\"Mrs. Rosalie Goldner\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1109.jpg\",\"id\":\"15\"},{\"createdAt\":\"2023-04-23T22:34:57.525Z\",\"name\":\"Cindy Koelpin\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/406.jpg\",\"id\":\"16\"},{\"createdAt\":\"2023-04-24T10:48:48.113Z\",\"name\":\"Woodrow Williamson\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/712.jpg\",\"id\":\"17\"},{\"createdAt\":\"2023-04-24T00:57:43.603Z\",\"name\":\"Kristi Satterfield\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/315.jpg\",\"id\":\"18\"},{\"createdAt\":\"2023-04-23T20:26:12.239Z\",\"name\":\"Miss Jill Brakus\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1099.jpg\",\"id\":\"19\"},{\"createdAt\":\"2023-04-24T11:59:15.215Z\",\"name\":\"Christy Monahan\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/452.jpg\",\"id\":\"20\"},{\"createdAt\":\"2023-04-24T09:22:44.409Z\",\"name\":\"Latoya Hammes\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/747.jpg\",\"id\":\"21\"},{\"createdAt\":\"2023-04-23T19:27:58.947Z\",\"name\":\"Pat McGlynn\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1133.jpg\",\"id\":\"22\"},{\"createdAt\":\"2023-04-23T16:44:33.052Z\",\"name\":\"Elizabeth Zboncak\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/569.jpg\",\"id\":\"23\"},{\"createdAt\":\"2023-04-24T10:05:19.598Z\",\"name\":\"Ms. Constance Hackett Jr.\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1059.jpg\",\"id\":\"24\"},{\"createdAt\":\"2023-04-24T07:55:11.013Z\",\"name\":\"Irvin Cummerata\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/708.jpg\",\"id\":\"25\"},{\"createdAt\":\"2023-04-24T02:09:34.331Z\",\"name\":\"Jan Stanton\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/987.jpg\",\"id\":\"26\"},{\"createdAt\":\"2023-04-24T04:20:43.153Z\",\"name\":\"Mable Kuphal\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/444.jpg\",\"id\":\"27\"},{\"createdAt\":\"2023-04-24T06:10:38.771Z\",\"name\":\"Paula Kshlerin\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1145.jpg\",\"id\":\"28\"},{\"createdAt\":\"2023-04-24T03:15:33.343Z\",\"name\":\"Roberto Blanda\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/575.jpg\",\"id\":\"29\"},{\"createdAt\":\"2023-04-23T18:20:58.632Z\",\"name\":\"Mr. Lisa Erdman\",\"avatar\":\"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1172.jpg\",\"id\":\"30\"}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the list of users and can count them\n",
      "Final Answer: The total number of users is 30.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = load_tools([\"requests_all\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "response = agent.run(\"Get the list of users at https://644696c1ee791e1e2903b0bb.mockapi.io/user and tell me the total number of users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-REPL\n",
    "\n",
    "Another tool feature in LangChain is the Python REPL tool, which allows you to execute Python code generated by the language model. This can be useful for complex calculations where the language model generates code to calculate the answer since LLMs are not good at solving algorithmic and math problems. \n",
    "\n",
    "Here’s an example of  Python-REPL tool usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to generate a list of random strings, sort them, and then print the result\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import random\n",
      "\n",
      "my_list = []\n",
      "for i in range(30):\n",
      "    my_list.append(''.join(random.choices(string.ascii_lowercase, k=4)))\n",
      "\n",
      "my_list.sort()\n",
      "print(my_list)\u001b[0mNameError(\"name 'string' is not defined\")\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mNameError(\"name 'string' is not defined\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to import the string module\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import random\n",
      "import string\n",
      "\n",
      "my_list = []\n",
      "for i in range(30):\n",
      "    my_list.append(''.join(random.choices(string.ascii_lowercase, k=4)))\n",
      "\n",
      "my_list.sort()\n",
      "print(my_list)\u001b[0m['cgdg', 'eqsv', 'fpgi', 'hpzj', 'hrpr', 'ivsi', 'jfwy', 'kxpk', 'lekv', 'lmwb', 'lsri', 'mbfl', 'mlvk', 'mogx', 'mxck', 'npjw', 'nsup', 'nwow', 'ofpj', 'pqzv', 'snti', 'soug', 'thdx', 'wyzv', 'xhqb', 'yani', 'youf', 'yxzn', 'zhno', 'zomz']\n",
      "\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m['cgdg', 'eqsv', 'fpgi', 'hpzj', 'hrpr', 'ivsi', 'jfwy', 'kxpk', 'lekv', 'lmwb', 'lsri', 'mbfl', 'mlvk', 'mogx', 'mxck', 'npjw', 'nsup', 'nwow', 'ofpj', 'pqzv', 'snti', 'soug', 'thdx', 'wyzv', 'xhqb', 'yani', 'youf', 'yxzn', 'zhno', 'zomz']\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: ['cgdg', 'eqsv', 'fpgi', 'hpzj', 'hrpr', 'ivsi', 'jfwy', 'kxpk', 'lekv', 'lmwb', 'lsri', 'mbfl', 'mlvk', 'mogx', 'mxck', 'npjw', 'nsup', 'nwow', 'ofpj', 'pqzv', 'snti', 'soug', 'thdx', 'wyzv', 'xhqb', 'yani', 'youf', 'yxzn', 'zhno', 'zomz']\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['cgdg', 'eqsv', 'fpgi', 'hpzj', 'hrpr', 'ivsi', 'jfwy', 'kxpk', 'lekv', 'lmwb', 'lsri', 'mbfl', 'mlvk', 'mogx', 'mxck', 'npjw', 'nsup', 'nwow', 'ofpj', 'pqzv', 'snti', 'soug', 'thdx', 'wyzv', 'xhqb', 'yani', 'youf', 'yxzn', 'zhno', 'zomz']\n"
     ]
    }
   ],
   "source": [
    "tools = load_tools([\"python_repl\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "print( agent.run(\"Create a list of random strings containing 4 letters, list should contain 30 examples, and sort the list alphabetically\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "The Wikipedia API tool in LangChain is a powerful tool that allows language models to interact with the Wikipedia API to fetch information and use it to answer questions. Be aware that you need to install the Wikipedia python package using the pip install Wikipedia command. The codes are tested using the 1.4.0 version. However, use the latest version of the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m He is a famous prophet\n",
      "Action: Python REPL\n",
      "Action Input: print(\"Nostradamus is known for his prophecies\")\u001b[0mNostradamus is known for his prophecies\n",
      "\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mNostradamus is known for his prophecies\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Nostradamus is known for his prophecies\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Nostradamus is known for his prophecies\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "tools = load_tools([\"wikipedia\"])\n",
    "\n",
    "print( agent.run(\"What is Nostradamus know for\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(name='Wikipedia', description='A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\edumu\\\\anaconda3\\\\envs\\\\llm-lc\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wolfram-Alpha\n",
    "\n",
    "In LangChain, you can integrate Wolfram Alpha by using the WolframAlphaAPIWrapper utility. First, you need to set up a Wolfram Alpha developer account and get your APP ID. \n",
    "\n",
    "Then, install the Wolfram Alpha Python library with pip install Wolframalpha.\n",
    "\n",
    "After that, you can set the Wolfram Alpha APP ID as an environment variable in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"your_app_id\"\n",
    "\n",
    "from langchain. utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "\n",
    "wolfram = WolframAlphaAPIWrapper()\n",
    "result = wolfram.run(\"What is 2x+5 = -3x + 7?\")\n",
    "print(result)  # Output: 'x = 2/5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the WolframAlphaAPIWrapper from the LangChain library, this code solves the algebraic equation. Let’s observe the WolframAlpha as a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wolfram-alpha\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "print( agent.run(\"How many days until the next Solar eclipse\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Showcase of Resourceful Collaboration\n",
    "\n",
    "Agents have the capability to employ a variety of tools in order to provide comprehensive and accurate responses to complex inquiries. These agents are better equipped to deliver well-rounded solutions by integrating resources such as Wikipedia and Wolfram-Alpha. Here’s an example of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wolfram-alpha\", \"wikipedia\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "\t\ttools,\n",
    "\t\tllm,\n",
    "\t\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\t\tverbose=True\n",
    "\t)\n",
    "\n",
    "agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
