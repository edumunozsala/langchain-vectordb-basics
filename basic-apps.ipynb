{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Applications Powered by LLMs with LangChain\n",
    "\n",
    "### Introduction\n",
    "\n",
    "LangChain is designed to assist developers in building end-to-end applications using language models. It offers an array of tools, components, and interfaces that simplify the process of creating applications powered by large language models and chat models. LangChain streamlines managing interactions with LLMs, chaining together multiple components, and integrating additional resources, such as APIs and databases. Having gained a foundational understanding of the library in previous lesson, let's now explore various examples of utilizing prompts to accomplish multiple tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of LangChain is its support for prompts, which encompasses prompt management, prompt optimization, and a generic interface for all LLMs. The framework also provides common utilities for working with LLMs.\n",
    "\n",
    "ChatPromptTemplate is used to create a structured conversation with the AI model, making it easier to manage the flow and content of the conversation. In LangChain, message prompt templates are used to construct and work with prompts, allowing us to exploit the underlying chat model's potential fully.\n",
    "\n",
    "System and Human prompts differ in their roles and purposes when interacting with chat models. SystemMessagePromptTemplate provides initial instructions, context, or data for the AI model, while HumanMessagePromptTemplate are messages from the user that the AI model responds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Inception\" is a science fiction action film directed by Christopher Nolan. It was released in 2010 and stars Leonardo DiCaprio, Joseph Gordon-Levitt, Ellen Page, Tom Hardy, and Marion Cotillard.\n",
      "\n",
      "The movie follows Dom Cobb (played by DiCaprio), a skilled thief who specializes in extracting valuable information from the subconscious of his targets by entering their dreams. Cobb is given a chance to redeem himself by performing the opposite task of \"inception\" – planting an idea in someone's mind instead of stealing it.\n",
      "\n",
      "The film explores the concept of shared dreaming and delves into the complexities of the human mind. It takes the audience on a thrilling journey through various dream levels, blurring the lines between reality and the dream world.\n",
      "\n",
      "\"Inception\" received critical acclaim for its originality, visual effects, and thought-provoking storyline. It was praised for its complex narrative structure and the performances of the cast. The film was a commercial success, grossing over $828 million worldwide.\n",
      "\n",
      "If you are interested in watching \"Inception,\" it is available on various streaming platforms and can be rented or purchased on digital platforms.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "template = \"You are an assistant that helps users find information about movies.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"Find information about the movie {movie_title}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "response = chat(chat_prompt.format_prompt(movie_title=\"Inception\").to_messages())\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization chain example:\n",
    "\n",
    "LangChain prompts can be found in various use cases, such as summarization or question-answering chains. For example, when creating a summarization chain, LangChain enables interaction with an external data source to fetch data for use in the generation step. This could involve summarizing a lengthy piece of text or answering questions using specific data sources.\n",
    "\n",
    "The following code will initialize the language model using OpenAI class with a temperature of 0 - because we want deterministic output.  The load_summarize_chain function accepts an instance of the language model and returns a pre-built summarization chain. Lastly, the PyPDFLoader class is responsible for loading PDF files and converting them into a format suitable for processing by LangChain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 17122 tokens (16866 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edumu\\Google Drive\\Github\\langchain-vectordb-basics\\basic-apps.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m document \u001b[39m=\u001b[39m document_loader\u001b[39m.\u001b[39mload()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Summarize the document\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m summary \u001b[39m=\u001b[39m summarize_chain(document)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(summary[\u001b[39m'\u001b[39m\u001b[39moutput_text\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[1;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_docs(\n\u001b[0;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mother_keys\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[0;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:87\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     86\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs), {}\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\llm.py:213\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     65\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     66\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 69\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\base.py:134\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m    130\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    133\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\base.py:191\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    192\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\base.py:185\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    180\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    181\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, invocation_params\u001b[39m=\u001b[39mparams\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 185\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    186\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    187\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\openai.py:314\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[0;32m    312\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39m, prompt\u001b[39m=\u001b[39m_prompts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    315\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 17122 tokens (16866 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from langchain import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Initialize language model\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Load the summarization chain\n",
    "summarize_chain = load_summarize_chain(llm)\n",
    "\n",
    "# Load the document using PyPDFLoader\n",
    "document_loader = PyPDFLoader(file_path=\"data/Retrieve rerank generate.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "# Summarize the document\n",
    "summary = summarize_chain(document)\n",
    "print(summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Re2G: Retrieve, Rerank, Generate\\nMichael Glass1, Gaetano Rossiello1, Md Faisal Mahbub Chowdhury1,\\nAnkita Rajaram Naik1 2,Pengshan Cai1 2,Alﬁo Gliozzo1\\n1IBM Research AI, Yorktown Heights, NY , USA\\n2University of Massachusetts Amherst, MA, USA\\nAbstract\\nAs demonstrated by GPT-3 and T5, transform-\\ners grow in capability as parameter spaces be-\\ncome larger and larger. However, for tasks\\nthat require a large amount of knowledge, non-\\nparametric memory allows models to grow dra-\\nmatically with a sub-linear increase in compu-\\ntational cost and GPU memory requirements.\\nRecent models such as RAG and REALM\\nhave introduced retrieval into conditional gen-\\neration. These models incorporate neural ini-\\ntial retrieval from a corpus of passages. We\\nbuild on this line of research, proposing Re2G,\\nwhich combines both neural initial retrieval\\nand reranking into a BART-based sequence-\\nto-sequence generation. Our reranking ap-\\nproach also permits merging retrieval results\\nfrom sources with incomparable scores, en-\\nabling an ensemble of BM25 and neural initial\\nretrieval. To train our system end-to-end, we\\nintroduce a novel variation of knowledge dis-\\ntillation to train the initial retrieval, reranker\\nand generation using only ground truth on the\\ntarget sequence output. We ﬁnd large gains in\\nfour diverse tasks: zero-shot slot ﬁlling, ques-\\ntion answering, fact checking and dialog, with\\nrelative gains of 9% to 34% over the previous\\nstate-of-the-art on the KILT leaderboard. We\\nmake our code available as open source1.\\n1 Introduction\\nGPT-3 [Brown et al., 2020] and T5 [Raffel et al.,\\n2020] are arguably the most powerful members\\nin a family of deep learning NLP models called\\ntransformers. Such models store surprising amount\\nof world knowledge. They have been shown to\\nproduce good performance on a range of demand-\\ning tasks, especially in generating human like texts.\\nHowever, such large transformers’ capability is\\ntied to the increasingly larger parameter spaces on\\nwhich they are trained.\\n1https://github.com/IBM/\\nkgi-slot-filling/tree/re2gRecently, there has been work towards trans-\\nformers that make use of non-parametric knowl-\\nedge. REALM (Retrieval Augmented Language\\nModel) [Guu et al., 2020] and RAG (Retrieval Aug-\\nmented Generation) [Lewis et al., 2020b] both use\\nan indexed corpus of passages to support condi-\\ntional generation. By using the corpus as a source\\nof knowledge these models can extend the informa-\\ntion available to the model by tens or even hundreds\\nof gigabytes with a sub-linear scaling in computa-\\ntion cost.\\nThese recent advancements, in turn, have\\nbeen inspired by BART (Bidirectional and Auto-\\nRegressive Transformer) [Lewis et al., 2020a] that\\ncombines a Bidirectional Encoder (e.g. BERT [De-\\nvlin et al., 2019]) with an Autoregressive decoder\\n(e.g. GPT [Brown et al., 2020]) into one sequence-\\nto-sequence model.\\nWe build on this line of research, pioneered\\nby REALM and RAG, and propose a new ap-\\nproach that we call Re2G(Retrieve, Rerank,\\nGenerate), which combines both neural initial re-\\ntrieval and reranking into a BART-based sequence-\\nto-sequence generation.\\nThere are two particular aspects on which our ap-\\nproach is different from the previous works. Firstly,\\nour reranking approach permits merging retrieval\\nresults from sources with incomparable scores, e.g.\\nenabling an ensemble of BM25 and neural initial\\nretrieval. Secondly, to train our system end-to-end,\\nwe introduce a novel variation of knowledge dis-\\ntillation to train the initial retrieval, reranker and\\ngeneration using only ground truth on the target\\nsequence output.\\nThe KILT benchmark [Petroni et al., 2021] has\\nbeen recently introduced to evaluate the capabili-\\nties of pre-trained language models to address NLP\\ntasks that require access to external knowledge. We\\nevaluate on four diverse tasks from KILT: slot ﬁll-\\ning, question answering, fact checking and dialog.\\nFigure 1 shows examples of these tasks. Re2GarXiv:2207.06300v1  [cs.CL]  13 Jul 2022', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 0}),\n",
       " Document(page_content='makes signiﬁcant gains on all four tasks, reaching\\nthe top of the KILT leaderboards and establishing\\na new state-of-the-art.\\nThe contributions of this work are as follows:\\n•We introduce Re2G, demonstrating the effec-\\ntiveness of reranking for generative language\\nmodels that incorporate retrieval.\\n•We further extend Re2Gby ensembling ini-\\ntial retrieval methods, combining neural and\\ntraditional keyword-based approaches.\\n• Re2Gimproves the current state-of-the-art of\\n9%, 31%, 34%, 22% and 10% relative gains\\non the headline KILT metrics for T-REx (slot\\nﬁlling), Natural Questions (question answer-\\ning), TriviaQA (question answering), FEVER\\n(fact checking), and Wizard of Wikipedia (di-\\nalog), respectively.\\n•We publicly release our code as open source\\nto support continued development.\\n2 Related Work\\nThe KILT benchmark and public leaderboard2com-\\nbines eleven datasets across ﬁve tasks. The main ad-\\nvantage of the KILT distribution of these datasets is\\nthat the provenance information from each dataset\\nis realigned to reference the same snapshot of\\nWikipedia. A uniﬁed evaluation script and set\\nof metrics is also provided. In this work, we\\nfocus on four tasks, such as Slot Filling [Levy\\net al., 2017, Elsahar et al., 2018], Question Answer-\\ning [Kwiatkowski et al., 2019, Joshi et al., 2017],\\nFact Checking [Thorne et al., 2018a,c], and Dia-\\nlog [Dinan et al., 2019] (see Figure 1).\\nA set of baseline methods have been proposed\\nfor KILT. GENRE [Cao et al., 2021] is trained\\non BLINK [Wu et al., 2020] and all KILT tasks\\njointly using a sequence-to-sequence language\\nmodel to generate the title of the Wikipedia page\\nwhere the answer can be found. This method is\\na strong baseline to evaluate the retrieval perfor-\\nmance, but it does not address the downstream\\ntasks. On the other hand, generative models, such\\nas BART [Lewis et al., 2020a] and T5 [Raffel et al.,\\n2020], show interesting performance when ﬁne-\\ntuned on the downstream tasks relying only on the\\nimplicit knowledge stored in the weights of the\\n2https://eval.ai/web/challenges/\\nchallenge-page/689/leaderboardneural networks, without the use of any explicit\\nretrieval component.\\nRAG [Lewis et al., 2020b], an end-to-end\\nretrieval-based generative model, is the best per-\\nforming baseline in KILT and it incorporates\\nDPR [Karpukhin et al., 2020] to ﬁrst retrieve rel-\\nevant passages for the query, then it uses a model\\ninitialized from BART [Lewis et al., 2020a] to per-\\nform a sequence-to-sequence generation from each\\nevidence passage concatenated with the query in\\norder to generate the answer. Figure 2 shows the\\narchitecture of RAG.\\nMulti-task DPR [Maillard et al., 2021] ex-\\nploits multi-task learning by training both DPR\\npassage and query encoder on all KILT tasks.\\nDensePhrases [Lee et al., 2021] addresses the\\nknowledge intensive tasks with a short answer, such\\nas slot ﬁlling. It indexes the phrases in the cor-\\npus that can be potential answers. The extracted\\nphrases are represented by their start and end to-\\nken vectors from the ﬁnal layer of a transformer\\ninitialized from SpanBERT [Joshi et al., 2020].\\nKnowledge Graph Induction (KGI) [Glass et al.,\\n2021] combines DPR and RAG models, both\\ntrained with task and dataset speciﬁc training. KGI\\nemploys a two phase training procedure: ﬁrst train-\\ning the DPR model, i.e. both the query and context\\nencoder, using the KILT provenance ground truth.\\nThen, KGI trains the sequence-to-sequence genera-\\ntion and further trains the query encoder using only\\nthe target output as the objective. This results in\\nlarge improvements in retrieval performance and,\\nas a consequence, in the downstream tasks.\\nKILT-WEB 2 [Piktus et al., 2021] addresses the\\nKILT tasks by broadening the knowledge source\\nused. Rather than rely only on KILT’s Wikipedia\\nsnapshot, KILT-WEB 2 creates SPHERE as a knowl-\\nedge source. SPHERE is built from CCNet [Wenzek\\net al., 2020] and over twenty times the size of the\\nWikipedia corpus. It can use either BM25 or DPR\\nretrieval (though not both combined) followed by\\na ‘reader’ component, but not trained end-to-end.\\nThe reader component is the Fusion-in-Decoder\\n[Izacard and Grave, 2021] model, where retrieved\\ndocuments are encoded independently, then their\\nencoded representations are concatenated for the\\ndecoder.\\nSEAL [Bevilacqua et al., 2022] introduces a\\nnovel generative approach to retrieval. Rather\\nthan generating the unique document identiﬁer like\\nGENRE, SEAL can generate any ngrams present', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 1}),\n",
       " Document(page_content='T-REx\\nInput:\\nDracula [SEP] narrative location\\nOutput: Transylvania\\nProvenance: 7923-2\\nNatural Questions\\nInput: when did bram stoker’s drac-\\nula come out\\nOutput: 1897\\nProvenance: 7923-1\\nFEVER\\nInput: Dracula is a novel by a Scot-\\ntish author.\\nOutput: REFUTES\\nProvenance: 7923-1Dracula (7923)\\nDracula is an 1897 Gothic horror novel by\\nIrish author Bram Stoker. It introduced the\\ncharacter of Count Dracula, and established\\nmany conventions of subsequent vampire fantasy.\\nThe novel tells the story of Dracula’s attempt\\nto move from Transylvania to England so that\\nhe may ﬁnd new blood and spread the undead\\ncurse, and of the battle between Dracula and a\\nsmall group of men and a woman led by Professor\\nAbraham Van Helsing.Wizard of Wikipedia\\nInput:\\n• I really like vampires!!\\n•Vampires are intense and based\\non European folklore. Do you\\nhave any favorite vampires?\\n• I think dracula is the best one!!!\\nOutput: He’s one of the best! He’s\\nbased on the character from the 1897\\nhorror book of the same name.\\nProvenance: 7923-1\\nFigure 1: KILT tasks of slot ﬁlling, question answering, fact checking and dialog\\nQueryMarginalization\\nQuery \\nEncoderAdd Query\\nTop-K\\nPassagesoutputANN\\nIndexGenerator\\nFigure 2: RAG Architecture\\nQueryMarginalization\\nQuery \\nEncoderAdd Query\\nTop-N\\nPassagesTop-K\\nPassagesoutputANN\\nIndex\\nBM25\\nIndexReranker Generator\\nFigure 3: Re2G Architecture\\nin the corpus, which are then mapped to passages.\\nThe neural retrieval generator is based on BART\\nand constrained to generate ngrams that appear\\nin the corpus with an FM-Index [Ferragina and\\nManzini, 2000]. Like KILT-WEB 2, SEAL uses\\nFusion-in-Decoder as the component responsible\\nfor generating the output conditioned on the re-\\ntrieved passages.\\nMulti-stage or cascade approaches to retrieval\\nhave received ample attention in Information Re-\\ntrieval (IR) research. The multi-stage approach\\nbegins with the initial retrieval phase, where an ini-\\ntial set of documents or passages form the pool of\\ncandidates to be considered for ranking. Then one\\nor more phases of increasingly computationally de-\\nmanding rerankers are applied. Early approaches in\\nlearning to rank [Liu, 2009] used features and linear\\nclassiﬁers. Pre-trained language models, especially\\nBERT [Devlin et al., 2019], have shown state-of-the-art performance when applied to the task of\\nrelevance ranking. Transformers may be applied as\\nclassiﬁers to each query and passage pair indepen-\\ndently [Nogueira and Cho, 2019] or as generators\\nto produce labels for passages in a sequence-to-\\nsequence model [Nogueira et al., 2020].\\n3 Methodology\\nThe approach of RAG, Multi-DPR, and KGI is\\nto train a neural IR (Information Retrieval) com-\\nponent and further train it end-to-end through its\\nimpact in generating the correct output. Figure 2\\nillustrates the end-to-end RAG system.\\nIt has been previously established that results\\nfrom initial retrieval can be greatly improved\\nthrough the use of a reranker [Liu, 2009, Wang\\net al., 2011]. Therefore we hypothesized that natu-\\nral language generation systems incorporating re-\\ntrieval can beneﬁt from reranking.', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 2}),\n",
       " Document(page_content='Linear Layer \\nand Softmax\\n[SEP]T[SEP]\\nE[SEP]…\\nE[CLS] E1 EN E[SEP] E’1 E’MC T1 TN T[SEP] T’1 T’M\\n[CLS] Query [SEP] Passage…\\n… … …… …\\nBERTFigure 4: Interaction Model Reranker\\nQuery Encoder (BERT)\\n[CLS]rq\\nQueryPassage Encoder (BERT)\\n[CLS]rp\\nPassageInner Product\\nFigure 5: Representation Model for Initial Retrieval\\nIn addition to improving the ranking of passages\\nreturned from DPR, a reranker can be used after\\nmerging the results of multiple retrieval methods\\nwith incomparable scores. For example, the scores\\nreturned by BM25 [Robertson and Zaragoza, 2009]\\nare not comparable to the inner products from DPR.\\nUsing the scores from a reranker, we can ﬁnd the\\ntop-k documents from the union of DPR and BM25\\nresults. Figure 3 illustrates our extension of RAG\\nwith a reranker. We call our system Re2G(Retrieve,\\nRerank, Generate).\\n3.1 Reranker\\nThe reranker we use is based on the sequence-pair\\nclassiﬁcation of Nogueira and Cho [2019]. This\\nmodel is shown in Figure 4. The query and passage\\nare input together to a BERT [Devlin et al., 2019]\\ntransformer. Cross attention is applied over the\\ntokens of both sequences jointly. This is called an\\ninteraction model.\\nThis model contrasts with the representation\\nmodel used for initial retrieval. Figure 5 shows\\nthe bi-encoder representation model for DPR. The\\nrepresentation vectors for the query and passage\\nare produced independently. This allows for ef-\\nﬁcient retrieval by pre-computing vectors for all\\npassages in the corpus and indexing them with an\\nANN (Approximate Nearest Neighbors) index. By\\nusing an interaction model to rerank the top-N pas-\\nsages from the representation model, we can get\\nthe advantages of both model types: accuracy and\\nscalability.\\nWe initialize the reranker from the BERT model\\ntrained on MS MARCO [Nguyen et al., 2016] by\\nNBoost [Thienes and Pertschuk, 2019] and avail-able through Hugging Face3.\\n3.2 Training\\nAs Figure 1 illustrates, KILT tasks are provided\\nwith two types of ground truth: the target output se-\\nquence and the provenance information indicating\\nthe passage or passages in the corpus that support\\nthe output.\\nOur training is carried out in four phases: DPR\\ntraining, generation training, reranking training,\\nand full end-to-end training. The initial DPR\\nand reranking phases make use of the provenance\\nground truth. The generation and full end-to-end\\ntraining make use of only the target output.\\nFormally:\\n•The original KILT instances are a tuple:\\nhq; t;Proviwhere qis the input or prompt,\\ntis the target output, and Prov is the set of\\nprovenance passages that support the target\\noutput.\\n•DPR training is a tuple: hq; p+; p\\x00iwhere\\np+2Prov andp\\x00where p\\x002BM25 (q)^\\np\\x00=2Prov\\n•Reranking training begins with the applica-\\ntion of DPR and BM25, producing tuples:\\nhq;P;Proviwhere P=BM25 (q)[DPR (q)\\n•Generation and end-to-end training instances\\nare pairs of query and target: hq; ti\\nThe ﬁrst two phases, DPR and generation, are\\nidentical to KGI, speciﬁcally KGI 0. We use the\\ncodes from Glass et al. [2021]4.\\nDPR Stage 1 training is the same training used\\nby Karpukhin et al. [2020]. The triplets of query,\\npositive passage and “hard negative” passages from\\nBM25 are put into batches of 128 instances. The\\npositives and hard negatives from other instances\\nform the “batch negatives” for each instance. The\\nDPR bi-encoder model gives each query a proba-\\nbility distribution over the positive, hard negative,\\nand batch negatives. The loss is the negative log-\\nlikelihood for the positive. After DPR Stage 1 train-\\ning the passages from the corpus are indexed with\\na Hierarchical Navigable Small World (HNSW)\\n[Malkov and Yashunin, 2018] using FAISS [John-\\nson et al., 2017].\\n3https://huggingface.co/nboost/\\npt-bert-base-uncased-msmarco\\n4https://github.com/IBM/\\nkgi-slot-filling', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 3}),\n",
       " Document(page_content='Generation training extends the training of\\nthe query encoder and trains the BART LARGE\\nsequence-to-sequence model on the target sequence\\noutput. This training is the same as that described\\nby Lewis et al. [2020b].\\n3.3 Reranking Training\\nThe next phase, training the reranking in isolation,\\nbegins with gathering the initial retrieval results\\nfrom DPR and BM25 on the training set. These\\nresults are merged and used as training data for the\\nreranker.\\nIn some datasets there are multiple positive\\npassages. Therefore, we use the negative of the\\nsummed log-likelihood for the positive passages as\\nthe loss function. The logits given by the reranker\\narezrand the indices for the correct passages (from\\nthe ground truth provenance) are Prov .\\nloss =\\x00X\\ni2Provlog(softmax (zr)i)\\n3.4 End-to-End Training\\nTraining end-to-end poses a special challenge. In\\nRAG, the gradient propagates to the query encoder\\nbecause the inner product between the query vec-\\ntor and the passage vector is used to weight the\\ninﬂuence of each sequence, a process RAG calls\\nmarginalization. The inputs to the BART model\\nare sequences ( sj=pj[SEP] q) that comprise a\\nquery qplus retrieved passage pj. The probability\\nfor each sequence is determined from the softmax\\nover the retrieval (or reranker) scores for the pas-\\nsage. The probability for each target token tigiven\\nthe sequence sjis a softmax over BART’s token\\nprediction logits. The loss therefore is a negative\\nlog-likelihood summed over all target tokens and\\nsequences, weighted by each sequence’s probabil-\\nity.\\nConsider that in Re2Gthe score from the\\nreranker, not the initial retrieval, is used to weight\\nthe impact of each sequence in generation. This al-\\nlows the reranker to be trained through the ground\\ntruth on target output, but it means the gradient for\\nthe query encoder will be zero since the marginal-\\nization no longer depends on the inner product from\\nthe query and passage representation vectors.P(sj) =softmax (zr)j\\nP(tijsj) =softmax (BART (sj)i)ti\\nloss =\\x00X\\ni;jlog(P(tijsj)\\x01P(sj))\\nWe consider three possible resolutions to this\\nissue.\\n• Combine the DPR and reranker scores\\n• Freeze the query encoder\\n• Online Knowledge Distillation\\nThe ﬁrst candidate solution is tempting but fa-\\ntally ﬂawed. By adding the log softmax from DPR\\nand the reranker we can ensure that both systems\\nare trained through impact in generation. However,\\nif the DPR score is added to the reranker score, then\\nthe DPR score is being trained to provide a com-\\nplementary signal to the reranker. Therefore, when\\nDPR is used to gather the candidate passages, it\\ndoes not give the highest scores to the passages that\\nare most likely to be relevant, but instead gives the\\nhighest scores to the passages the reranker is most\\nlikely to underrate. We ﬁnd that this theoretical\\nconcern is also a practical concern, as DPR perfor-\\nmance (and overall system performance) declines\\ngreatly when trained in this way.\\nThe simplest solution is to freeze the parameters\\nof the query encoder, training only the reranker\\nand generation components. We ﬁnd this is indeed\\nthe best solution for one of our datasets, Wizard of\\nWikipedia. Note that DPR has already been trained\\nin two phases, ﬁrst from the provenance ground\\ntruth and then again in generation training in the\\nRAG model.\\nThe third solution is our novel application of\\nknowledge distillation [Hinton et al., 2015]. We use\\nthe reranker as a teacher model to provide labels to\\nthe DPR student model. We distill the knowledge\\nacross architectures: from an interaction model\\nto a representation model. Further, this knowl-\\nedge distillation occurs online, while the reranker\\nis being trained. The loss for the initial retrieval is\\ntherefore the KL-divergence between the probabil-\\nity distribution it gives over the retrieved passages\\nand the reranker’s probability distribution over the\\nsame passages. A temperature hyperparameter T\\nsmooths these distributions to prevent excessive\\nloss and stabilize training.', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 4}),\n",
       " Document(page_content='T-REx (Slot Filling)\\nR-Prec Recall@5 Accuracy F1 KILT-AC KILT-F1\\nRe2G (ours) 80.70 89.00 87.68 89.93 75.84 77.05\\nKGI 1[Glass et al., 2021] 74.36 83.14 84.36 87.24 69.14 70.58\\nKILT-WEB 2 [Piktus et al., 2021] 75.64 87.57 81.34 84.46 64.64 66.64\\nSEAL [Bevilacqua et al., 2022] 67.80 81.52 83.72 86.53 60.08 61.72\\nKGI 0[Glass et al., 2021] 59.70 70.38 77.90 81.31 55.54 56.79\\nNatural Questions (Question Answering)\\nR-Prec Recall@5 Accuracy F1 KILT-AC KILT-F1\\nRe2G (ours) 70.78 76.63 51.73 60.97 43.56 49.80\\nSEAL [Bevilacqua et al., 2022] 63.16 68.19 53.74 62.24 38.78 44.40\\nKGI 0[Glass et al., 2021] 63.71 70.17 45.22 53.38 36.36 41.83\\nKILT-WEB 2 [Piktus et al., 2021] 59.83 71.17 51.59 60.83 35.32 40.73\\nRAG [Petroni et al., 2021] 59.49 67.06 44.39 52.35 32.69 37.91\\nTriviaQA (Question Answering)\\nR-Prec Recall@5 Accuracy F1 KILT-AC KILT-F1\\nRe2G (ours) 72.68 74.23 76.27 81.40 57.91 61.78\\nSEAL [Bevilacqua et al., 2022] 68.36 76.36 70.86 77.29 50.56 54.99\\nKILT-WEB 2 [Piktus et al., 2021] 58.85 71.55 72.73 79.54 45.55 49.57\\nKGI 0[Glass et al., 2021] 60.49 63.54 60.99 66.55 42.85 46.08\\nMultiDPR [Maillard et al., 2021] 61.49 68.33 59.60 66.53 42.36 46.19\\nFEVER (Fact Checking)\\nR-Prec Recall@5 Accuracy KILT-AC\\nRe2G (ours) 88.92 92.52 89.55 78.53\\nSEAL [Bevilacqua et al., 2022] 81.45 89.56 89.54 71.28\\nKILT-WEB 2 [Piktus et al., 2021] 74.77 87.89 88.99 65.68\\nKGI 0[Glass et al., 2021] 75.60 84.95 85.58 64.41\\nMultiDPR [Maillard et al., 2021] 74.48 87.52 86.32 63.94\\nWizard of Wikipedia (Dialog)\\nR-Prec Recall@5 Rouge-L F1 KILT-RL KILT-F1\\nHindsight [Paranjape et al., 2021] 56.08 74.27 17.06 19.19 11.92 13.39\\nRe2G (ours) 60.10 79.98 16.76 18.90 11.39 12.98\\nSEAL [Bevilacqua et al., 2022] 57.55 78.96 16.65 18.34 10.45 11.63\\nKGI 0[Glass et al., 2021] 55.37 78.45 16.36 18.57 10.36 11.79\\nRAG [Petroni et al., 2021] 57.75 74.61 11.57 13.11 7.59 8.75\\nKILT-WEB 2 [Piktus et al., 2021] 41.54 68.25 13.94 15.66 6.55 7.57\\nTable 1: KILT leaderboard top systems\\nloss =DKL\\x10\\nsoftmax\\x10zs\\nT\\x11\\r\\r\\rsoftmax\\x10zt\\nT\\x11\\x11\\n\\x01T2\\nThe knowledge distillation has the usual advan-\\ntage of providing signal not only of positive and\\nnegative instances, but degrees of negativeness. In\\naddition, since we retrieve n= 12 passages from\\nDPR but only use the top- k(k= 5) for generation,\\nthe knowledge distillation loss is providing a (soft)\\nlabel for more passages.3.5 Inference\\nAt inference time the query is encoded using the\\nDPR query encoder and the top-12 passages from\\nthe HNSW index are returned. The query is also\\npassed to BM25 search, speciﬁcally Anserini5,\\ngathering the top-12 BM25 results. Both sets of\\npassages are passed to the reranker and scored. The\\ntop-5 passages are then joined with the query and\\npassed to BART LARGE to generate the output. The\\nﬁve output sequences are weighted according to\\nthe softmax over the reranker scores to produce the\\n5https://github.com/castorini/anserini', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 5}),\n",
       " Document(page_content='ﬁnal output.\\n4 Experiments\\nWe test our model on ﬁve datasets, over four dis-\\ntinct tasks in the KILT benchmark: slot ﬁlling,\\nquestion answering, fact checking and dialog. Fig-\\nure 1 shows an example of these four tasks.\\nThe slot ﬁlling dataset, T-REx [Elsahar et al.,\\n2018], provides as input a head entity and relation,\\nand expects as output the entity or term that ﬁlls the\\nslot, also called the tail entity. The T-REx dataset\\ncontains 2.3M instances. We use only 370k training\\ninstances by downsampling the relations that occur\\nmore than 5000 times. This reduces the training\\ntime required while keeping state-of-the-art perfor-\\nmance. The development and test sets each have\\n5k instances.\\nThe question answering datasets are “open” ver-\\nsions of Natural Questions [Kwiatkowski et al.,\\n2019] and TriviaQA [Joshi et al., 2017]. Unlike\\nthe original versions, the relevant Wikipedia page\\nmust be found by a retrieval step. The training sets\\nfor Natural Questions and TriviaQA contain 87k\\nand 62k questions, with another 3k and 5k for the\\ndevelopment and 1.4k and 6.5k for test.\\nThe fact checking dataset in KILT is FEVER\\n(Fact Extraction and VERiﬁcation). It is a com-\\nbination of the two FEVER versions [Thorne\\net al., 2018b, 2019] omitting the NOTENOUGH -\\nINFO class. There are approximately 10k instances\\nin the development and test sets, and 100k for train-\\ning. FEVER is a classiﬁcation task, but we cast it as\\na generation task by training the model to generate\\neither the token “SUPPORTS” or “REFUTES”.\\nWizard of Wikipedia [Dinan et al., 2018] is the\\ndialog dataset. The input is a short dialog history\\nending with the information seeker’s turn. The ex-\\npected output is a fact presented conversationally\\nor just an utterance or question mentioning content\\nfrom a relevant Wikipedia page. It is the smallest\\ndataset with approximately 3k instances in devel-\\nopment and test and 64k in train.\\nFor all tasks, systems are expected to produce the\\ntarget output as well as justify it with provenance\\ninformation from the KILT knowledge source. The\\nmetrics of R-Precision and Recall@5 measure the\\ncorrectness of the provenance. R-Precision mea-\\nsures what fraction of the Rdocuments in the\\nground truth provenance ( jProvj=R) are present\\nin the top- Rdocuments returned by the system.\\nAccuracy and (token-level) F1 measure the cor-rectness of the generated output. For Wizard of\\nWikipedia, Rouge-L [Lin, 2004] is used instead of\\naccuracy, since systems are very unlikely to gen-\\nerate the exact target output. The metrics of KILT-\\nAccuracy, KILT-F1 and, for Wizard of Wikipedia,\\nKILT-Rouge-L are the underlying metric (e.g. Ac-\\ncuracy) for instances where R-Precision is one, oth-\\nerwise zero. These metrics indicate output correct-\\nness when provenance is also correctly supplied.\\nTable 1 shows the performance of Re2Gon the\\nKILT leaderboard. We achieved 9%, 31%, 34%,\\n22% and 10% relative gains over the previous state-\\nof-the-art on the headline KILT metrics for T-REx,\\nNatural Questions, TriviaQA, FEVER, and Wizard\\nof Wikipedia, respectively. Furthermore, Re2Ghas\\nheld the lead in the headline KILT metrics in all\\ndatasets except for Wizard of Wikipedia where it is\\nnow second best.\\nSince our submission to the KILT leaderboard\\nfor the Wizard of Wikipedia, a new system called\\nHindsight [Paranjape et al., 2021] achieved even\\nbetter results on the generation metrics on that par-\\nticular task. The new system of SEAL has also\\nachieved top results for some metrics on the Natu-\\nral Questions and TriviaQA benchmarks.\\n4.1 Retrieval\\nTable 2 examines how the retrieval improves\\nthrough each step of training. In the ﬁrst half of the\\ntable we consider the initial retrieval alone. DPR\\nStage 1 is the DPR training described earlier - train-\\ning only from the provenance ground truth with\\nbatch negatives and hard negatives from BM25.\\nKGI 0further trains the query encoder of DPR Stage\\n1 through its impact in generating the target output.\\nFinally Re2Gextends the training of DPR with on-\\nline knowledge distillation from the reranker. This\\nstep is beneﬁcial in two of the three datasets, while\\nthe previous steps improve performance across all\\ndatasets.\\nIn the second half of the table we examine the\\nimprovement in reranking. The baseline of KGI 0\\nDPR+BM25 merges the results of KGI 0’s DPR and\\nBM25 by scoring each passage by the sum of the in-\\nverse rank from each method. For both T-REx and\\nFEVER, even this simple approach to ensembling\\nDPR and BM25 improves Recall@5, although not\\nR-Precision. Following reranker training using the\\nprovenance ground truth (Reranker Stage 1), we\\nﬁnd improvement over DPR across all ﬁve datasets\\non both retrieval metrics. The reranker’s improve-', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 6}),\n",
       " Document(page_content='T-REx NQ TriviaQA FEVER WoW\\nR-Prec R@5 R-Prec R@5 R-Prec R@5 R-Prec R@5 R-Prec R@5\\nBM25 46.88 69.59 24.99 42.57 26.48 45.57 42.73 70.48 27.44 45.74\\nDPR Stage 1 49.02 63.34 56.64 64.38 60.12 64.04 75.49 84.66 34.74 60.22\\nKGI 0DPR 65.02 75.52 64.65 69.60 60.55 63.65 80.34 86.53 48.04 71.02\\nRe2G DPR 67.16 76.42 65.88 70.90 62.33 65.72 84.13 87.90 47.09 69.88\\nKGI 0DPR+BM25 60.48 80.06 36.91 66.94 40.81 64.79 65.95 90.34 35.63 68.47\\nReranker Stage 1 81.22 87.00 70.78 73.05 71.80 71.98 87.71 92.43 55.50 74.98\\nRe2G Reranker 81.24 88.58 70.92 74.79 60.37 70.61 90.06 92.91 57.89 74.62\\nTable 2: Development Set Results for Retrieval\\nment following end-to-end training is mixed. In\\nFEVER and Wizard of Wikipedia there is substan-\\ntial gain in R-Precision, approximately 2%. T-REx\\nand Natural Questions are ﬂat. However, there is a\\nsharp decline in the performance of TriviaQA, in\\nretrieval metrics. This is true despite the fact that\\nretrieving these passages greatly improves answer\\naccuracy and F1. This suggests some incomplete-\\nness in the provenance ground truth for TriviaQA.\\n4.2 Ablations\\nTable 3 explores ablations of the Re2Gsystem. The\\npoint estimates and 95% conﬁdence intervals are\\nreported. Re2G-KD excludes the online knowl-\\nedge distillation, instead freezing the query encoder\\nwhen training the reranker and generator during\\nend-to-end training. Re2G-BM25 excludes BM25\\nresults, fetching 24 passages from DPR rather than\\n12 from DPR and 12 from BM25. The passages are\\nstill reranked. KGI 0is the baseline system, without\\na reranker and therefore also without BM25 results\\nor online knowledge distillation during training.\\nBoth online knowledge distillation and ensem-\\nbling with BM25 improve performance in four\\nout of ﬁve datasets. Online knowledge distillation\\nfailed to improve for Wizard of Wikipedia and en-\\nsembling with BM25 failed to improve for Natural\\nQuestions.\\n5 Analysis\\nSince the Re2Gmodel differs from the KGI model\\nonly in the retrieval phase, we hypothesized that\\nits gains in output quality are driven by its better\\nretrieval quality. To test this hypothesis we con-\\nsidered all cases where the Re2Gmodel produces\\nbetter output than the KGI 0model and calculated\\nthe fraction of such cases where Re2G’s rank for\\nthe ﬁrst correct passage is lower than KGI 0’s.\\nWe ﬁnd that for T-REx, NQ, and FEVER the\\nfractions of output gains that could be attributed toimproved retrieval and ranking are 67.73%, 61.08%\\nand 66.86% respectively. While for TriviaQA and\\nWizard of Wikipedia only 36.86% and 27.74% of\\noutput improvements were accompanied by im-\\nproved ranking for the correct passage. It is impor-\\ntant to note that in Wizard of Wikipedia, many of\\nthese improved outputs have only a small gain in\\ntoken-level F1.\\nWhile much of the gain in output quality is at-\\ntributable to improved recall, at least a third is\\nnot. This reinforces an observation of Glass et al.\\n[2021], that models trained with better retrieval\\ncan produce better output even when the retrieved\\npassages are equivalent at test time.\\n5.1 Slot ﬁlling error analysis\\nTo understand the types of errors Re2Gmakes we\\nsampled 50 instances of the development set of the\\nT-REx dataset where the Accuracy and token-level\\nF1 score was zero.\\nInterestingly, the most common class of er-\\nror (33/50) was due to the incompleteness of the\\nground truth. Often the head entity is ambiguous\\n(19/50), or the relation has multiple ﬁllers (16/50).\\nAs an example, consider the following where there\\nare two Joe O’Donnell notable for sports in the\\npassages retrieved, and each played for at least two\\ndifferent teams.\\nJoe O’Donnell [SEP] member of sports team\\nTarget: Buffalo Bills\\nRe2G: Dumbarton F.C.\\n\\x0fJoe O’Donnell (footballer) / Joe O’Donnell\\n(footballer) Joseph ’Joe’ O’Donnell (born 3\\nMarch 1961) was a Scottish footballer who played\\nforDumbarton and Stranraer.\\n\\x0fJoe O’Donnell (American football) / ... fullback,\\nguard and tackle for the University of Michigan\\nfrom 1960 to 1963. He also played professional\\nfootball as a guard and tackle for eight seasons\\nfor the Buffalo Bills ...\\nWhen Re2Gproduces genuine errors it is usually', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 7}),\n",
       " Document(page_content='T-REx (Slot Filling)\\nR-Prec Recall@5 Accuracy F1 KILT-AC KILT-F1\\nRe2G 81.24\\x061.08 88.58 \\x060.84 86.60\\x060.94 89.20 \\x060.81 75.66 \\x061.19 77.08 \\x061.15\\nRe2G-KD 81.08\\x061.09 88.84 \\x060.83 87.00\\x060.93 89.46 \\x060.80 75.72 \\x061.19 77.00 \\x061.15\\nRe2G-BM25 71.92\\x061.25 78.67 \\x061.10 79.48\\x061.12 82.52 \\x061.00 66.58 \\x061.31 67.93 \\x061.28\\nKGI 065.02\\x061.32 75.52 \\x061.16 77.52\\x061.16 80.91 \\x061.03 60.18 \\x061.36 61.38 \\x061.34\\nNatural Questions (Question Answering)\\nR-Prec Recall@5 Accuracy F1 KILT-AC KILT-F1\\nRe2G 70.92\\x061.67 74.79 \\x061.27 46.70\\x061.84 62.44 \\x061.65 39.23 \\x061.80 50.90 \\x061.76\\nRe2G-KD 69.72\\x061.69 73.73 \\x061.30 46.56\\x061.84 61.68 \\x061.67 38.24 \\x061.79 49.93 \\x061.76\\nRe2G-BM25 70.88\\x061.67 74.39 \\x061.28 46.70\\x061.84 61.98 \\x061.66 39.41 \\x061.80 50.91 \\x061.76\\nKGI 064.65\\x061.76 69.60 \\x061.39 40.50\\x061.81 55.07 \\x061.71 32.96 \\x061.73 42.87 \\x061.75\\nTriviaQA (Question Answering)\\nR-Prec Recall@5 Accuracy F1 KILT-AC KILT-F1\\nRe2G 72.01\\x061.20 73.16 \\x060.98 74.01\\x061.17 80.86 \\x060.99 56.04 \\x061.33 60.91 \\x061.27\\nRe2G-KD 72.01\\x061.20 73.16 \\x060.98 73.80\\x061.18 80.62 \\x061.00 56.04 \\x061.33 60.84 \\x061.28\\nRe2G-BM25 71.10\\x061.21 68.60 \\x061.03 68.59\\x061.24 76.68 \\x061.08 52.85 \\x061.34 58.37 \\x061.29\\nKGI 061.13\\x061.31 63.12 \\x061.08 60.68\\x061.31 66.61 \\x061.20 44.00 \\x061.33 47.35 \\x061.31\\nFEVER (Fact Checking)\\nR-Prec Recall@5 Accuracy KILT-AC\\nRe2G 90.06\\x060.53 92.91 \\x060.47 91.05\\x060.55 80.56 \\x060.76\\nRe2G-KD 89.85\\x060.54 92.48 \\x060.48 90.78\\x060.55 80.14 \\x060.77\\nRe2G-BM25 88.36\\x060.57 88.46 \\x060.59 90.63\\x060.56 78.74 \\x060.78\\nKGI 080.34\\x060.73 86.53 \\x060.63 87.84\\x060.63 70.06 \\x060.88\\nWizard of Wikipedia (Dialog)\\nR-Prec Recall@5 Rouge-L F1 KILT-RL KILT-F1\\nRe2G 56.48\\x061.76 74.00 \\x061.56 17.29\\x060.52 19.35 \\x060.57 11.37 \\x060.58 12.75 \\x060.63\\nRe2G-KD 57.89\\x061.75 74.62 \\x061.54 17.26\\x060.52 19.39 \\x060.57 11.61 \\x060.58 13.14 \\x060.64\\nRe2G-BM25 55.83\\x061.76 72.72 \\x061.58 17.15\\x060.51 19.17 \\x060.56 11.13 \\x060.57 12.52 \\x060.63\\nKGI 048.04\\x061.77 71.02 \\x061.61 16.75\\x060.48 19.04 \\x060.53 9.48 \\x060.53 10.74 \\x060.59\\nTable 3: Development Set Results for Re2G Variations\\nbecause it has selected some entity as a ﬁller related\\nin a different way (6/17) or it has failed to retrieve\\nthe necessary passage (9/17).\\n6 Conclusions\\nRe2Gconsiderably advanced the state-of-the-art\\nacross ﬁve KILT datasets, and still holds the top po-\\nsition in four of the ﬁve. Relative to previous work,\\nsuch as RAG or KGI,Re2Gsubstantially improves\\nboth in retrieval and end-to-end performance on\\nslot ﬁlling, question answering, fact checking, and\\ndialog. The reranker alone improves performance\\nand enables the inclusion of multiple sources of\\ninitial retrieval. This architecture permits us to\\nintegrate results from BM25, further improving ac-\\ncuracy. Our online knowledge distillation is able\\nto improve the performance of DPR in four of theﬁve datasets, despite the loss in end-to-end training\\nnot depending on the DPR scores. Similarly, the\\nensembling of DPR and BM25, which is enabled\\nby our incorporation of a reranker, beneﬁts four\\nof the ﬁve datasets tested. We have directed our\\nefforts towards improving the retrieval of relevant\\nknowledge. This also enables improvement in end-\\nto-end performance by supplying better passages\\nto the generation component.\\nFurther experiments on domain adaptation of\\nRe2Gon tasks like question answering or dialog\\nmight provide useful insight on the application of\\nthis technology to real world use cases. We are\\nreleasing our source code as open source (Apache\\n2.0 license) to enable further research.', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 8}),\n",
       " Document(page_content='References\\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick\\nLewis, Wen tau Yih, Sebastian Riedel, and Fabio\\nPetroni. Autoregressive search engines: Gener-\\nating substrings as document identiﬁers. ArXiv ,\\nabs/2204.10628, 2022.\\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\\nGretchen Krueger, Tom Henighan, Rewon Child,\\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\\nClemens Winter, Christopher Hesse, Mark Chen,\\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\\nChess, Jack Clark, Christopher Berner, Sam Mc-\\nCandlish, Alec Radford, Ilya Sutskever, and Dario\\nAmodei. Language models are few-shot learners. In\\nNeurIPS , 2020.\\nNicola De Cao, Gautier Izacard, Sebastian Riedel, and\\nFabio Petroni. Autoregressive entity retrieval. In\\nInternational Conference on Learning Representa-\\ntions . OpenReview.net, 2021. URL https://\\nopenreview.net/forum?id=5k8F6UU39V .\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. BERT: Pre-training of deep\\nbidirectional transformers for language understand-\\ning. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association\\nfor Computational Linguistics: Human Language\\nTechnologies, Volume 1 (Long and Short Papers) ,\\npages 4171–4186, Minneapolis, Minnesota, June\\n2019. Association for Computational Linguistics.\\ndoi: 10.18653/v1/N19-1423. URL https://\\naclanthology.org/N19-1423 .\\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\\nFan, Michael Auli, and Jason Weston. Wizard\\nof wikipedia: Knowledge-powered conversational\\nagents. In International Conference on Learning\\nRepresentations , 2018.\\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\\nFan, Michael Auli, and Jason Weston. Wizard\\nof wikipedia: Knowledge-powered conversational\\nagents. In ICLR (Poster) . OpenReview.net, 2019.\\nHady Elsahar, Pavlos V ougiouklis, Arslen Remaci,\\nChristophe Gravier, Jonathon Hare, Frederique\\nLaforest, and Elena Simperl. T-REx: A large\\nscale alignment of natural language with knowl-\\nedge base triples. In Proceedings of the Eleventh\\nInternational Conference on Language Resources\\nand Evaluation (LREC 2018) , Miyazaki, Japan,\\nMay 2018. European Language Resources Associ-\\nation (ELRA). URL https://aclanthology.\\norg/L18-1544 .\\nP. Ferragina and G. Manzini. Opportunistic data struc-\\ntures with applications. In Proceedings 41st An-\\nnual Symposium on Foundations of Computer Sci-\\nence, pages 390–398, 2000. doi: 10.1109/SFCS.\\n2000.892127.Michael Glass, Gaetano Rossiello, Md Faisal Mah-\\nbub Chowdhury, and Alﬁo Gliozzo. Ro-\\nbust retrieval augmented generation for zero-\\nshot slot ﬁlling. In Proceedings of the 2021\\nConference on Empirical Methods in Natural\\nLanguage Processing , pages 1939–1949, Online\\nand Punta Cana, Dominican Republic, Novem-\\nber 2021. Association for Computational Lin-\\nguistics. doi: 10.18653/v1/2021.emnlp-main.\\n148. URL https://aclanthology.org/\\n2021.emnlp-main.148 .\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pa-\\nsupat, and Ming-Wei Chang. Realm: Retrieval-\\naugmented language model pre-training. arXiv\\npreprint arXiv:2002.08909 , 2020.\\nGeoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. Dis-\\ntilling the knowledge in a neural network. In NIPS\\nDeep Learning and Representation Learning Work-\\nshop , 2015. URL http://arxiv.org/abs/\\n1503.02531 .\\nGautier Izacard and Edouard Grave. Leveraging pas-\\nsage retrieval with generative models for open do-\\nmain question answering. In Proceedings of the\\n16th Conference of the European Chapter of the\\nAssociation for Computational Linguistics: Main\\nVolume , pages 874–880, Online, April 2021. As-\\nsociation for Computational Linguistics. doi: 10.\\n18653/v1/2021.eacl-main.74. URL https://\\naclanthology.org/2021.eacl-main.74 .\\nJeff Johnson, Matthijs Douze, and Hervé Jégou.\\nBillion-scale similarity search with gpus. arXiv\\npreprint arXiv:1702.08734 , 2017.\\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\\nZettlemoyer. TriviaQA: A large scale distantly su-\\npervised challenge dataset for reading comprehen-\\nsion. In Proceedings of the 55th Annual Meeting of\\nthe Association for Computational Linguistics (Vol-\\nume 1: Long Papers) , pages 1601–1611, Vancouver,\\nCanada, July 2017. Association for Computational\\nLinguistics. doi: 10.18653/v1/P17-1147. URL\\nhttps://aclanthology.org/P17-1147 .\\nMandar Joshi, Danqi Chen, Yinhan Liu, Daniel S.\\nWeld, Luke Zettlemoyer, and Omer Levy. Span-\\nBERT: Improving pre-training by representing and\\npredicting spans. Transactions of the Associa-\\ntion for Computational Linguistics , 8:64–77, 2020.\\ndoi: 10.1162/tacl_a_00300. URL https://\\naclanthology.org/2020.tacl-1.5 .\\nVladimir Karpukhin, Barlas Oguz, Sewon Min,\\nPatrick Lewis, Ledell Wu, Sergey Edunov, Danqi\\nChen, and Wen-tau Yih. Dense passage re-\\ntrieval for open-domain question answering. In\\nProceedings of the 2020 Conference on Em-\\npirical Methods in Natural Language Process-\\ning (EMNLP) , pages 6769–6781, Online, Novem-\\nber 2020. Association for Computational Lin-\\nguistics. doi: 10.18653/v1/2020.emnlp-main.\\n550. URL https://aclanthology.org/\\n2020.emnlp-main.550 .', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 9}),\n",
       " Document(page_content='Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\\nﬁeld, Michael Collins, Ankur Parikh, Chris Al-\\nberti, Danielle Epstein, Illia Polosukhin, Jacob De-\\nvlin, Kenton Lee, Kristina Toutanova, Llion Jones,\\nMatthew Kelcey, Ming-Wei Chang, Andrew M.\\nDai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.\\nNatural questions: A benchmark for question an-\\nswering research. Transactions of the Association\\nfor Computational Linguistics , 7:452–466, March\\n2019. doi: 10.1162/tacl_a_00276. URL https:\\n//aclanthology.org/Q19-1026 .\\nJinhyuk Lee, Mujeen Sung, Jaewoo Kang, and Danqi\\nChen. Learning dense representations of phrases\\nat scale. In Proceedings of the 59th Annual Meet-\\ning of the Association for Computational Linguis-\\ntics and the 11th International Joint Conference\\non Natural Language Processing (Volume 1: Long\\nPapers) , pages 6634–6647, Online, August 2021.\\nAssociation for Computational Linguistics. doi:\\n10.18653/v1/2021.acl-long.518. URL https://\\naclanthology.org/2021.acl-long.518 .\\nOmer Levy, Minjoon Seo, Eunsol Choi, and Luke\\nZettlemoyer. Zero-shot relation extraction via\\nreading comprehension. In Proceedings of the\\n21st Conference on Computational Natural Lan-\\nguage Learning (CoNLL 2017) , pages 333–342,\\nVancouver, Canada, August 2017. Association for\\nComputational Linguistics. doi: 10.18653/v1/\\nK17-1034. URL https://aclanthology.\\norg/K17-1034 .\\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\\nGhazvininejad, Abdelrahman Mohamed, Omer\\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\\nBART: Denoising sequence-to-sequence pre-\\ntraining for natural language generation, translation,\\nand comprehension. In Proceedings of the 58th An-\\nnual Meeting of the Association for Computational\\nLinguistics , pages 7871–7880, Online, July 2020a.\\nAssociation for Computational Linguistics. doi:\\n10.18653/v1/2020.acl-main.703. URL https://\\naclanthology.org/2020.acl-main.703 .\\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\\nrich Küttler, Mike Lewis, Wen-tau Yih, Tim\\nRocktäschel, Sebastian Riedel, and Douwe Kiela.\\nRetrieval-augmented generation for knowledge-\\nintensive nlp tasks. In H. Larochelle, M. Ranzato,\\nR. Hadsell, M. F. Balcan, and H. Lin, editors, Ad-\\nvances in Neural Information Processing Systems ,\\nvolume 33, pages 9459–9474. Curran Associates,\\nInc., 2020b.\\nChin-Yew Lin. Rouge: A package for automatic evalu-\\nation of summaries. In Text summarization branches\\nout, pages 74–81, 2004.\\nTie-Yan Liu. Learning to rank for information retrieval.\\nInformation Retrieval , 3(3):225–331, 2009.\\nJean Maillard, Vladimir Karpukhin, Fabio Petroni,\\nWen-tau Yih, Barlas Oguz, Veselin Stoyanov, andGargi Ghosh. Multi-task retrieval for knowledge-\\nintensive tasks. In ACL/IJCNLP (1) , pages 1098–\\n1111. Association for Computational Linguistics,\\n2021.\\nYu A Malkov and Dmitry A Yashunin. Efﬁcient and\\nrobust approximate nearest neighbor search using\\nhierarchical navigable small world graphs. IEEE\\ntransactions on pattern analysis and machine intelli-\\ngence , 42(4):824–836, 2018.\\nTri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao,\\nSaurabh Tiwary, Rangan Majumder, and Li Deng.\\nMs marco: A human generated machine reading\\ncomprehension dataset. In CoCo@ NIPS , 2016.\\nRodrigo Nogueira and Kyunghyun Cho. Passage re-\\nranking with bert. arXiv preprint arXiv:1901.04085 ,\\n2019.\\nRodrigo Nogueira, Zhiying Jiang, Ronak Pradeep,\\nand Jimmy Lin. Document ranking with a pre-\\ntrained sequence-to-sequence model. In Find-\\nings of the Association for Computational Lin-\\nguistics: EMNLP 2020 , pages 708–718, Online,\\nNovember 2020. Association for Computational Lin-\\nguistics. doi: 10.18653/v1/2020.ﬁndings-emnlp.\\n63. URL https://aclanthology.org/\\n2020.findings-emnlp.63 .\\nAshwin Paranjape, Omar Khattab, Christopher Potts,\\nMatei Zaharia, and Christopher D Manning. Hind-\\nsight: Posterior-guided training of retrievers for\\nimproved open-ended generation. arXiv preprint\\narXiv:2110.07752 , 2021.\\nFabio Petroni, Aleksandra Piktus, Angela Fan, Patrick\\nLewis, Majid Yazdani, Nicola De Cao, James\\nThorne, Yacine Jernite, Vladimir Karpukhin, Jean\\nMaillard, Vassilis Plachouras, Tim Rocktäschel, and\\nSebastian Riedel. KILT: a benchmark for knowl-\\nedge intensive language tasks. In Proceedings of\\nthe 2021 Conference of the North American Chap-\\nter of the Association for Computational Linguistics:\\nHuman Language Technologies , pages 2523–2544,\\nOnline, June 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.naacl-main.\\n200. URL https://aclanthology.org/\\n2021.naacl-main.200 .\\nAleksandra Piktus, Fabio Petroni, Vladimir Karpukhin,\\nDmytro Okhonko, Samuel Broscheit, Gautier Izac-\\nard, Patrick Lewis, Barlas O ˘guz, Edouard Grave,\\nWen-tau Yih, et al. The web is your oyster–\\nknowledge-intensive nlp against a very large web\\ncorpus. arXiv preprint arXiv:2112.09924 , 2021.\\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\\nine Lee, Sharan Narang, Michael Matena, Yanqi\\nZhou, Wei Li, and Peter J. Liu. Exploring the limits\\nof transfer learning with a uniﬁed text-to-text trans-\\nformer, 2020.\\nStephen Robertson and Hugo Zaragoza. The prob-\\nabilistic relevance framework: Bm25 and be-\\nyond. Found. Trends Inf. Retr. , 3(4):333–389,', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 10}),\n",
       " Document(page_content='April 2009. ISSN 1554-0669. doi: 10.1561/\\n1500000019. URL http://dx.doi.org/10.\\n1561/1500000019 .\\nCole Thienes and Jack Pertschuk. Nboost: Neu-\\nral boosting search results. https://github.\\ncom/koursaros-ai/nboost , 2019.\\nJames Thorne, Andreas Vlachos, Christos\\nChristodoulopoulos, and Arpit Mittal. FEVER:\\na large-scale dataset for fact extraction and veriﬁca-\\ntion. In NAACL-HLT , pages 809–819. Association\\nfor Computational Linguistics, 2018a.\\nJames Thorne, Andreas Vlachos, Christos\\nChristodoulopoulos, and Arpit Mittal. Fever:\\na large-scale dataset for fact extraction and veri-\\nﬁcation. In Proceedings of the 2018 Conference\\nof the North American Chapter of the Association\\nfor Computational Linguistics: Human Language\\nTechnologies, Volume 1 (Long Papers) , pages\\n809–819, 2018b.\\nJames Thorne, Andreas Vlachos, Oana Cocarascu,\\nChristos Christodoulopoulos, and Arpit Mittal. The\\nfact extraction and veriﬁcation (FEVER) shared task.\\nCoRR , abs/1811.10971, 2018c.\\nJames Thorne, Andreas Vlachos, Oana Cocarascu,\\nChristos Christodoulopoulos, and Arpit Mittal. The\\nfever2. 0 shared task. In Proceedings of the Sec-\\nond Workshop on Fact Extraction and VERiﬁcation\\n(FEVER) , pages 1–6, 2019.\\nLidan Wang, Jimmy Lin, and Donald Metzler. A cas-\\ncade ranking model for efﬁcient ranked retrieval. In\\nProceedings of the 34th international ACM SIGIR\\nconference on Research and development in Infor-\\nmation Retrieval , pages 105–114, 2011.\\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis Con-\\nneau, Vishrav Chaudhary, Francisco Guzmán, Ar-\\nmand Joulin, and Edouard Grave. CCNet: Ex-\\ntracting high quality monolingual datasets from web\\ncrawl data. In Proceedings of the 12th Language\\nResources and Evaluation Conference , pages 4003–\\n4012, Marseille, France, May 2020. European Lan-\\nguage Resources Association. ISBN 979-10-95546-\\n34-4. URL https://aclanthology.org/\\n2020.lrec-1.494 .\\nLedell Wu, Fabio Petroni, Martin Josifoski, Se-\\nbastian Riedel, and Luke Zettlemoyer. Scal-\\nable zero-shot entity linking with dense entity\\nretrieval. In Proceedings of the 2020 Confer-\\nence on Empirical Methods in Natural Language\\nProcessing (EMNLP) , pages 6397–6407, Online,\\nNovember 2020. Association for Computational\\nLinguistics. doi: 10.18653/v1/2020.emnlp-main.\\n519. URL https://aclanthology.org/\\n2020.emnlp-main.519 .Appendix\\nA Hyperparameters\\nWe have not done hyperparameter tuning for DPR\\nStage 1, Generation, or Reranking training. Instead\\nwe used hyperparameters similar to the original\\nworks on training DPR, BERT reranking and RAG.\\nTable 4 shows the hyperparameters used in our\\nexperiments.\\nFor knowledge distillation we used the same\\nhyperparameter settings as Generation. For the\\nadditional hyperparameters in online knowledge\\ndistillation: temperature and KD learn rate scaling,\\nwe experimented with temperatures of 10 and 40\\nand KD learn rate scaling of 1.0 and 0.1. For our\\nreported results we used a temperature of 10:0and\\na learn rate scaling of 1:0.\\nWhen training using online knowledge distilla-\\ntion, there is a separate optimizer for the query\\nencoder while training generation. This optimizer\\nuses the same hyperparameter settings.\\nTable 6 shows the settings for retrieval and gen-\\neration used for all datasets.\\nAll results are from a single run. The random\\nseed for python, numpy and pytorch was 42.\\nB Software Details\\nWe used the following software versions:\\n• Ubuntu 18\\n• Pytorch 1.7\\n• Transformers 4.3.2\\n• Anserini 0.4.1\\n(commit\\n3a60106fdc83473d147218d78ae7dca7c3b6d47c)\\nC Model Details\\nNumber of parameters Re2Guses three\\nBERT BASE transformers: query encoder, passage\\nencoder and reranker. Each has 110Mparameters.\\nThe generation component is a BART LARGE\\nmodel with 400Mparameters. There are 730M\\nparameters in total.\\nComputing infrastructure Using a single\\nNVIDIA V100 GPU DPR training of two epochs\\ntakes approximately 24 hours for T-REx and less\\nthan 12 hours for FEVER and WoW.\\nUsing a two NVIDIA P100 GPUs generation\\ntraining for 370k T-REx instances takes two days,', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 11}),\n",
       " Document(page_content='Hyperparameter DPR Reranker Generation\\nlearn rate 5e-5 3e-5 3e-5\\nbatch size 128 32 128\\nepochs 2 1 1*\\nwarmup instances 0 10% 10%\\nlearning schedule linear triangular triangular\\nmax grad norm 1 1 1\\nweight decay 0 0 0\\nAdam epsilon 1e-8 1e-8 1e-8\\nTable 4: Re2G hyperparameters\\nwhile FEVER and WoW training completes in half\\na day.\\nThe FAISS index on the KILT knowledge source\\nrequires a machine with large memory, we use ma-\\nchines with 128GB of memory.\\nD Generation Analysis\\nWe examined 20 instances coupled with 3 output\\ntexts: the baseline KGI 0,Re2G, and the target\\ntext in the ground-truth. The three output texts\\nwere presented unlabeled and in random order to\\navoid bias. For each instance, we read the conver-\\nsation history and then mark each text either GOOD ,\\nOKorINCONSISTENT generation. To our surprise,\\n5/20 ground-truth target texts are INCONSISTENT\\nwhich indicates the WoW benchmark might have\\nlimitations in annotation quality. Both the sys-\\nHyperparameter Value\\ntype IndexHNSWSQ\\nm 128\\nef search 128\\nef construction 200\\nindex batch size 100000\\nscalar quantizer 8\\nTable 5: FAISS index hyperparameters\\nHyperparameter Value\\nDPR passages 12\\nBM25 passages 12\\nBART sequences 5\\nBART beam size 6\\nBART length penalty 1.0\\nBART minimum length 2\\nBART maximum length 64\\nTable 6: Inference hyperparameterstems have similar results (GOOD/OK/INCONSISTENT\\n- Re2G: 8/2/10; KGI 0: 9/2/9) .\\nSecond, we checked a set of 20 WoW instances\\nwhere Re2G’s F1 score was in the bottom quin-\\ntile. The conversation history was presented along\\nwith Re2Ggenerated text and the passages re-\\ntrieved. Manual examination showed 8/20 as\\nINCONSISTENT and in 4/8 cases supporting ground-\\ntruth passages were not retrieved. Below is one\\nof the 12/20 cases where Re2Ggenerated text was\\nfound CONSISTENT with respect to the conversation\\nhistory, although it has low F1 and Rouge-L scores.\\nConversation History:\\n• My favorite color is red.\\n•Red is at the end of the spectrum of light,\\nits with orange and opposite of violet.\\n•I didn’t know that. What else do you know\\nabout red?\\nTarget: It’s actually a primary color for the RGB\\nand CMYK color model.\\nRe2G: It has a dominant wavelength of approxi-\\nmately 625-740 nanometres.\\nD.1 Generation Quality\\nTable 7 shows couple of examples that were part of\\nthe set of randomly selected instances from WoW\\ndataset and used for manual inspection. We choose\\nthese two particular instances to show when we\\nthought the ground truth (i.e. target) is not coher-\\nent with respect to the corresponding conversation\\nhistory.\\nIn the ﬁrst example, the system generated out-\\nputs were judged as coherent. We found that both\\nRe2GandKGI 0retrieved the following passage\\nwhich might have helped generation of the above\\noutput -\\nHorseshoe Falls / Horseshoe Falls\\nHorseshoe Falls, also known as Cana-\\ndian Falls, is the largest of the three wa-\\nterfalls that collectively form Niagara', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 12}),\n",
       " Document(page_content='Falls on the Niagara River along the\\nCanada–United States border. Approx-\\nimately 90% of the Niagara River, af-\\nter diversions for hydropower generation,\\nﬂows over Horseshoe Falls. The remain-\\ning 10% ﬂows over American Falls and\\nBridal Veil Falls. It is located between\\nTerrapin Point on Goat Island in the US\\nstate of New York, and Table Rock in the\\nCanadian province of Ontario. Section:\\nInternational border.\\nAs for the ground truth, we marked it (factu-\\nally) inconsistent based on the following retrieved\\npassage -\\nNiagara Falls / Located on the Niagara\\nRiver, which drains Lake Erie into Lake\\nOntario, the combined falls have the\\nhighest ﬂow rate of any waterfall in\\nNorth America that has a vertical drop of\\nmore than . During peak daytime tourist\\nhours, more than 168,000 m ( six million\\ncubic feet ) of water goes over the crest of\\nthe falls every minute. Horseshoe Falls\\nis the most powerful waterfall in North\\nAmerica, as measured by ﬂow rate.\\nIn the second example, all three texts were\\nmarked inconsistent. Interestingly, all the items in\\nthe conversation contains subjective opinion. Con-\\nsequently, all the three candidate texts also contains\\nsubjective opinion. The problem is both the sys-\\ntems generated texts that are almost repetition of\\nearlier conversation. In case of the ground truth,\\nwe ﬁnd that the text is semantically incoherent.\\nWe have also submitted ﬁles that contain all in-\\nstances that were used to generate the different\\nanalysis reported in Section 4.2 of the paper. These\\nﬁles also contains our annotations/remarks where\\napplicable.', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 13}),\n",
       " Document(page_content='Conversation history:\\n•Have you ever been to Niagra Falls? I want to go there, but I know it’s very far. Those beautiful\\n3 waterfalls are right between New York and Ontario, thousands of miles from me!\\n• I never have but I would love to. It looks beautiful.\\n•Yes, they do! They are different sized waterfalls, named Horseshoe, American and Bridal Veil\\nFalls.\\n• I had no idea. I’ve never heard that before. Very cool.\\n• Yes, and Horseshoe Falls in actually the most powerful waterfall in all of the US!\\n•I never new any details about it. I have just seen it in pictures and on TV and it looks very neat.\\nRe2G:Horseshoe falls, also known as Canadian Falls, is the largest of the three waterfalls that\\ncollectively form Niagara Falls on the Niagara River along with American Falls and Bridal Veil\\nFalls.\\n[GOOD]\\nKGI 0:Horseshoe falls is also known as Canadian Falls, which straddles the international border\\nbetween Canada and the U.S.\\n[GOOD]\\nGround truth: It’s really quite interesting and beautiful. There’s over six million cubic feet of\\nwater that crosses the fall’s crest every 60 seconds. Can you imagine?\\n[INCONSISTENT - 6M cubic feet of water crosses for the 3\\nwaterfalls combined, not just Horseshoe falls.]\\nConversation history:\\n• I love the taste of pasta mixed with tomato sauce and shredded cheese all over it\\n• I just love mines with chunky tomatoes mixed with meatballs and mushrooms.\\n•Olive Garden is the place that makes the best pastas. I try to visit the place as much I can with\\nmy friends\\n• I love Olive Garden especially the original one in Orlando they opened in 1982.\\n• I think Italians have special genes that makes them so adept at preparing pastas\\n•I believe so as well I would love to visit Argentina that is where Italian-born people reside great\\npasta I bet.\\n•I don’t know how they do it, but no matter how hard I try to prepare one at home, mine ends up\\nwith some peculiar taste\\nRe2G:I don’t know how they do it but I love the taste of pasta mixed with tomato sauce and\\nshredded cheese all over it\\n[INCONSISTENT - Dialogue repetition]\\nKGI 0:I just love the taste of pasta mixed with tomato sauce and shredded cheese all over it\\n[INCONSISTENT - Dialogue repetition]\\nGround truth: The taste is so full of an abundance of taste it just can’t be copied lol.\\n[INCONSISTENT - Semantically incoherent text “taste is full of ..\\ntaste”.]\\nTable 7: Some of the randomly selected instances from WoW benchmark that were evaluated by a human evaluator.\\nThe comments inside [..] are the feedback provided by the evaluator.', metadata={'source': 'data/Retrieve rerank generate.pdf', 'page': 14})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a web URL as document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This article discusses the GPTQ quantization method for compressing large language models. GPTQ is a post-training quantization method that can compress models to 2, 3, or 4 bits per parameter without sacrificing accuracy. The article explains the process of quantizing a fine-tuned Llama 2 7B model using the GPTQ methodology integrated with the transformers library. It also highlights the advantages and limitations of GPTQ and provides instructions on how to load and use the quantized model. The author shares their experience with quantizing the model and compares the performance of the quantized model with the original model.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "#loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "loader = WebBaseLoader(\"https://medium.com/towards-artificial-intelligence/gptq-quantization-on-a-llama-2-7b-fine-tuned-model-with-huggingface-a7b291fbb871\")\n",
    "docs = loader.load()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 4168 tokens (3912 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edumu\\Google Drive\\Github\\langchain-vectordb-basics\\basic-apps.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Summarize the document\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m summary \u001b[39m=\u001b[39m summarize_chain(docs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/basic-apps.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(summary[\u001b[39m'\u001b[39m\u001b[39moutput_text\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[1;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_docs(\n\u001b[0;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mother_keys\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[0;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:87\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     86\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs), {}\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\llm.py:213\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     65\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     66\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 69\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\chains\\llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\base.py:134\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m    130\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    133\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\base.py:191\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    192\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\base.py:185\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    180\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    181\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, invocation_params\u001b[39m=\u001b[39mparams\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 185\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    186\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    187\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\openai.py:314\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[0;32m    312\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39m, prompt\u001b[39m=\u001b[39m_prompts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    315\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\langchain\\llms\\openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4168 tokens (3912 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# Initialize language model\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Load the summarization chain\n",
    "summarize_chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# Load the document using WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://medium.com/towards-artificial-intelligence/gptq-quantization-on-a-llama-2-7b-fine-tuned-model-with-huggingface-a7b291fbb871/\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Summarize the document\n",
    "summary = summarize_chain(docs)\n",
    "print(summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mention early, we can reach the limit of the context length. We will deal with this issue in a later lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA chain example:\n",
    "\n",
    "We can also use LangChain to manage prompts for asking general questions from the LLMs. These models are proficient in addressing fundamental inquiries. Nevertheless, it is crucial to remain mindful of the potential issue of hallucinations, where the models may generate non-factual information. To address this concern, we will later introduce the Retrieval chain as a means to overcome this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom prompt template by creating an instance of the PromptTemplate class. The template string contains a placeholder {question} for the input question, followed by a newline character and the \"Answer:\" label.  The input_variables argument is set to the list of available placeholders in the prompt (like a question in this case) to indicate the name of the variable that the chain will replace in the template.run() method.\n",
    "\n",
    "We then instantiate an OpenAI model named text-davinci-003 with a temperature of 0. The OpenAI class is used to create the instance, and the model_name and temperature arguments are provided. Finally, we create a question-answering chain using the LLMChain class. \n",
    "\n",
    "The class constructor takes two arguments: llm, which is the instantiated OpenAI model, and prompt, which is the custom prompt template we defined earlier. \n",
    "\n",
    "By following these steps, we can process input questions effectively with the custom question-answering, generating appropriate answers using the OpenAI model and the custom prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The meaning of life is subjective and can vary from person to person. For some, it may be to find happiness and fulfillment, while for others it may be to make a difference in the world. Ultimately, the meaning of life is up to each individual to decide.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
