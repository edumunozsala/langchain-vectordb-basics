{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assisting Blog Posts Automatically with LangChain and Google Search\n",
    "\n",
    "## Introduction\n",
    "\n",
    "These days, artificial intelligence is changing the copywriting field by serving as a writing assistant. These language models can find spelling or grammatical errors, change tones, summarize, or even extend the content. However, there are times when the model may not have the specialized knowledge in a particular field to provide expert-level suggestions for extending parts of an article.\n",
    "\n",
    "In this lesson, we will take you step by step through the process of building an application that can effortlessly expand text sections. The process begins by asking an LLM (ChatGPT) to generate a few search queries based on the text at hand. These queries are then will be used to search the Internet using Google Search API that, captures relevant information on the subject. Lastly, the most relevant results will be presented as context to the model to suggest better content.\n",
    "\n",
    "We've got three variables here that hold an article's title and content (text_all). (From Artificial Intelligence News) Also, the text_to_change variable specifies which part of the text we want to expand upon. These constants are mentioned as a reference and will remain unchanged throughout the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
    "\n",
    "text_all = \"\"\" Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models. Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial. Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
    "\n",
    "text_to_change = \"\"\" Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate candidate search queries from the selected paragraph that we want to expand. The queries are then used to extract relevant documents using a search engine (e.g. Bing or Google Search), which are the split into small chunks. We then compute embeddings of these chunks and save chunks and embeddings in a Deep Lake dataset. Last, the most similar chunks to the paragraph that we want to expand are retrieved from Deep Lake, and used in a prompt to expand the paragraph with further knowledge.\n",
    "\n",
    "\n",
    "Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken. Refer to the course introduction if you are looking for the specific versions we used to write the codes in this lesson. Additionally, install the newspaper3k package with version 0.2.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Search Queries\n",
    "\n",
    "The code below uses OpenAI’s ChatGPT model to process an article and suggest three relevant search phrases. We define a prompt that asks the model to suggest Google search queries that could be used to with finding more information about the subject. The LLMChain ties the ChatOpenAI model and ChatPromptTemplate together to create the chain to communicate with the model. Lastly, it splits the response by newline and removes the first characters to extract the data. The mentioned format works because we asked the API to generate each query in a new line that starts with -. (It is possible to achieve the same effect by using the OutputParser class) Prior to running the code provided below, make sure to store your OpenAI key in the OPENAI_API_KEY environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI voice cloning software and its applications in speech synthesis', 'Implications of AI on elections, jobs, and security', 'Transformative nature of AI and its potential in various industries']\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"\"\" You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
    "Write 3 queries as a bullet point list, prepending each line with -.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title\n",
    "})\n",
    "\n",
    "queries = [line[2:] for line in response.split(\"\\n\")]\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Search Results\n",
    "\n",
    "We must set up the API Key and a custom search engine to be able to use Google search API. To get the key, head to the Google Cloud console and generate the key by pressing the CREATE CREDENTIALS buttons from the top and choosing API KEY. Then, head to the Programmable Search Engine dashboard and remember to select the “Search the entire web” option. The Search engine ID will be visible in the details. You might also need to enable the “Custom Search API” service under the Enable APIs and services. (You will receive the instruction from API if required) We can now configure the environment variables GOOGLE_CSE_ID and GOOGLE_API_KEY, allowing the Google wrapper to connect with the API.\n",
    "\n",
    "\n",
    "The next step is to use the generated queries from the previous section to get a number of sources from Google searches. The LangChain library provides the GoogleSearchAPIWrapper utility that takes care of receiving search results and makes a function to run it top_n_results. Then, the Tool class will create a wrapper around the said function to make it compatible with agents and help them to interact with the outside world. We only ask for the top 5 results and concatenate the results for each query in the all_results variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "# Remember to set the \"GOOGLE_CSE_ID\" and \"GOOGLE_API_KEY\" environment variable.\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULTS = 5\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULTS)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top_n_results\n",
    ")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query in queries:\n",
    "    results = tool.run(query)\n",
    "    all_results += results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The all_results variable holds 15 web addresses. (3 queries from ChatGPT x 5 top Google search results) However, it is not optimal flow to use all the contents as a context in our application. There are technical, financial, and contextual considerations to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'ElevenLabs - Generative AI Text to Speech & Voice Cloning', 'link': 'https://elevenlabs.io/', 'snippet': 'AI Voice Generator and Research Lab. Generate high-quality text to speech in any voice, style and language with the most powerful AI speech tool ever.'}, {'title': 'Free AI Voice Cloning In 30 Seconds! No Sign-up Required.', 'link': 'https://speechify.com/voice-cloning/', 'snippet': \"Once you are done, it's a one-click auto, almost instantaneous conversion to speech. This is why it's the best voice cloning tool in the market. Listen to your\\xa0...\"}, {'title': 'Speech synthesis - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Speech_synthesis', 'snippet': '... the use of text-to-speech programs. Synthesizer technologies. The most ... \"Artificial Imposters—Cybercriminals Turn to AI Voice Cloning for a New Breed of Scam\".'}, {'title': 'Text to Speech – Realistic AI Voice Generator | Microsoft Azure', 'link': 'https://azure.microsoft.com/en-us/products/ai-services/text-to-speech', 'snippet': '... use AI voice generators to speak naturally using synthesized speech. Engage ... Speech Synthesis Markup Language (SSML) or with the audio content creation tool.'}, {'title': 'Best AI Voice Cloning Software For Free - Voice.AI', 'link': 'https://voice.ai/voice-cloning', 'snippet': 'Thanks to the art of speech synthesis you could even clone your voice and then apply it to singing audio in order to hear yourself singing better than you\\xa0...'}, {'title': 'Blumenthal & Hawley to Hold Hearing on Oversight of Artificial ...', 'link': 'https://www.blumenthal.senate.gov/newsroom/press/release/blumenthal-and-hawley-to-hold-hearing-on-oversight-of-artificial-intelligence', 'snippet': \"Oct 5, 2023 ... “Artificial intelligence will be transformative in ways we can't even imagine, with implications for Americans' elections, jobs, and security,”\\xa0...\"}, {'title': 'Priorities for a National AI Strategy - Center for American Progress', 'link': 'https://www.americanprogress.org/article/priorities-for-a-national-ai-strategy/', 'snippet': 'Aug 10, 2023 ... ... election infrastructure and ensuring AI system vendor security standards. ... impacts of AI systems on election administration and election dis\\xa0...'}, {'title': 'Unleashing possibilities, ignoring risks: Why we need tools to ...', 'link': 'https://www.brookings.edu/articles/unleashing-possibilities-ignoring-risks-why-we-need-tools-to-manage-ais-impact-on-jobs/', 'snippet': 'Aug 17, 2023 ... Astonishingly, most frameworks for impact assessments largely overlook the impact of AI on jobs. ... AI accountability and election integrity |\\xa0...'}, {'title': 'Blueprint for an AI Bill of Rights | OSTP | The White House', 'link': 'https://www.whitehouse.gov/ostp/ai-bill-of-rights/', 'snippet': 'Algorithmic discrimination occurs when automated systems contribute to unjustified different treatment or impacts disfavoring people based on their race, color,\\xa0...'}, {'title': 'Understanding the impact of automation on workers, jobs, and wages', 'link': 'https://www.brookings.edu/articles/understanding-the-impact-of-automation-on-workers-jobs-and-wages/', 'snippet': 'Jan 19, 2022 ... ... A conversation with Congresswoman ... “Good jobs” should pay well and offer both advancement possibility and some security.'}, {'title': 'The transformative potential of artificial intelligence - ScienceDirect', 'link': 'https://www.sciencedirect.com/science/article/pii/S0016328721001932', 'snippet': \"GPTs are thought to drive economic growth across many sectors due to their ... In order to have productive discussions about the scale and nature of AI's\\xa0...\"}, {'title': 'How artificial intelligence is transforming the world | Brookings', 'link': 'https://www.brookings.edu/articles/how-artificial-intelligence-is-transforming-the-world/', 'snippet': 'Apr 24, 2018 ... The dual-use nature of many AI algorithms will mean AI research ... These examples from a variety of sectors demonstrate how AI is transforming\\xa0...'}, {'title': 'Transforming healthcare with AI: The impact on the workforce and ...', 'link': 'https://www.mckinsey.com/industries/healthcare/our-insights/transforming-healthcare-with-ai', 'snippet': \"Mar 10, 2020 ... Artificial intelligence (AI) has the potential to transform how healthcare is delivered. A joint report with the European Union's EIT Health\\xa0...\"}, {'title': 'Artificial intelligence in healthcare: transforming the practice of ...', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8285156/', 'snippet': 'Automation and ambient clinical intelligence: AI systems leveraging natural ... Advances in AI have the potential to transform many aspects of healthcare\\xa0...'}, {'title': 'Economic potential of generative AI | McKinsey', 'link': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier', 'snippet': 'Jun 14, 2023 ... For now, however, foundation models lack the capabilities to help design products across all industries. In addition to the productivity gains\\xa0...'}]\n"
     ]
    }
   ],
   "source": [
    "print(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Most Relevant Results\n",
    "\n",
    "As mentioned before, Google Search will return the URL for each source. However, we need the content of these pages. The newspaper package can extract the contents of a web link using the .parse() method. The following code will loop through the results and attempt to extract the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  13\n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "\n",
    "pages_content = []\n",
    "\n",
    "for result in all_results:\n",
    "\ttry:\n",
    "\t\tarticle = newspaper.Article(result[\"link\"])\n",
    "\t\tarticle.download()\n",
    "\t\tarticle.parse()\n",
    "\n",
    "\t\tif len(article.text) > 0:\n",
    "\t\t\tpages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
    "\texcept:\n",
    "\t\tcontinue\n",
    "\n",
    "print(\"Number of pages: \", len(pages_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that 13 pages were processed while we expected 15. There are specific scenarios in which the newspaper library may encounter difficulties extracting information. These include search results that lead to a PDF file or websites that restrict access to web scraping.\n",
    "\n",
    "\n",
    "Now, it is crucial to split the saved contents into smaller chunks to ensure the articles do not exceed the model’s input length. The code below splits the text by either newline or spaces, depending on the situation. It makes sure that each chunk has 3000 characters with 100 overlaps between the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  134\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
    "        docs.append(new_doc)\n",
    "\n",
    "print(\"Number of chunks: \", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, 134 chunks of data are in the docs variable. It is time to find the most relevant chunks to pass them as context to the large language model. The OpenAIEmbeddings class will use OpenAI to convert the texts into vector space that holds semantics. We proceeded to embed both document chunks and the desired sentence from the main article that was chosen for expansion. The selected sentence was chosen at the beginning of this lesson and represented by the text_to_change variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(text_to_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the distance between the high-dimensionality embedding vectors is possible using the cosine similarity metric. It determines how close two points are within the vector space. Since the embeddings contain contextual information, their proximity indicates a shared meaning. So, the document with a higher similarity score can be used as the source.\n",
    "\n",
    "We used the cosine_similarity function from the sklearn library. It calculates the distance between each chunk and the chosen sentence to return the index of the best three results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "    # convert the lists of vectors to numpy arrays\n",
    "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "    query_vector = np.array(query_vector)\n",
    "\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "    # sort the vectors based on cosine similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # retrieve the top K indices from the sorted list\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "top_k = 3\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend the Sentence\n",
    "\n",
    "We can now define the prompt using the additional information from Google search. There are six input variables in the template:\n",
    "\n",
    "- title that holds the main article’s title;\n",
    "- text_all to present the whole article we are working on;\n",
    "- text_to_change is the selected part of the article that requires expansion;\n",
    "- doc_1, doc_2, doc_3 to include the close Google search results as context.\n",
    "\n",
    "The remaining part of the code should be familiar, as it follows the same structure used for generating Google queries. It defines a HumanMessage template to be compatible with the ChatGPT API, which is defined with a high-temperature value to encourage creativity. The LLMChain class will create a chain that combines the model and prompt to finish up the process by using .run() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Change:   Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
      "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. In fact, Blumenthal and Hawley will convene a hearing titled \"Oversight of AI: Rules for Artificial Intelligence\" to discuss the importance of establishing rules and safeguards for AI. Blumenthal even played an audio introduction using an AI voice cloning software trained on his speeches to demonstrate the potential of the technology. This hearing will include testimony from Sam Altman, the CEO of OpenAI, who has emphasized the need for AI regulation and safety measures. It is clear that there is a growing concern about the risks associated with AI and the potential impact it could have on democratic institutions. Efforts are being made to protect against these threats and ensure that AI is used responsibly in areas like election administration, where AI systems should undergo rigorous testing and certification processes administered by relevant agencies.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
    "----------------\n",
    "{doc_1}\n",
    "----------------\n",
    "{doc_2}\n",
    "----------------\n",
    "{doc_3}\n",
    "----------------\n",
    "\n",
    "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title,\n",
    "    \"doc_1\": best_k_documents[0].page_content,\n",
    "    \"doc_2\": best_k_documents[1].page_content,\n",
    "    \"doc_3\": best_k_documents[2].page_content\n",
    "})\n",
    "\n",
    "print(\"Text to Change: \", text_to_change)\n",
    "print(\"Expanded Variation:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
