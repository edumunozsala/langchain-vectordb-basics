{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Customer Support Question Answering Chatbot\n",
    "\n",
    "## Introduction\n",
    "\n",
    "As we witness accelerated technological progress, large language models like GPT-4 and ChatGPT have emerged as significant breakthroughs in the tech landscape. These state-of-the-art models demonstrate exceptional prowess in content generation. However, they are not without their share of challenges, such as biases and hallucinations. Despite these limitations, LLMs have the potential to bring about a transformative impact on chatbot development.\n",
    "\n",
    "Traditional, primarily intent-based chatbots have been designed to respond to specific user intents. These intents comprise a collection of sample questions and corresponding responses. For instance, a \"Restaurant Recommendations\" intent might include sample questions like \"Can you suggest a good Italian restaurant nearby?\" or \"Where can I find the best sushi in town?\" with responses such as \"You can try the Italian restaurant 'La Trattoria' nearby\" or \"The top-rated sushi place in town is 'Sushi Palace.'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "This project aims to build a chatbot that leverages GPT3 to search for answers within documents. The workflow for the experiment is explained in the following diagram.\n",
    "\n",
    "First we scrape some content from online articles, we split them into small chunks, compute their embeddings and store them in Deep Lake. Then, we use a user query to retrieve the most relevant chunks from Deep Lake, we put them into a prompt, which will be used to generate the final answer by the LLM.\n",
    "\n",
    "It is important to note that there is always a risk of generating hallucinations or false information when using LLMs. Although this might not be acceptable for many customers support use cases, the chatbot can still be helpful for assisting operators in drafting answers that they can double-check before sending them to the user.\n",
    "\n",
    "In the next steps, we'll explore how to manage conversations with GPT-3 and provide examples to demonstrate the effectiveness of this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import SeleniumURLLoader, WebBaseLoader\n",
    "\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use information from the following articles\n",
    "urls = ['https://beebom.com/what-is-nft-explained/',\n",
    "        'https://beebom.com/how-delete-spotify-account/',\n",
    "        'https://beebom.com/how-download-gif-twitter/',\n",
    "        'https://beebom.com/how-use-chatgpt-linux-terminal/',\n",
    "        'https://beebom.com/how-delete-spotify-account/',\n",
    "        'https://beebom.com/how-save-instagram-story-with-music/',\n",
    "        'https://beebom.com/how-install-pip-windows/',\n",
    "        'https://beebom.com/how-check-disk-usage-linux/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Split the documents into chunks and compute their embeddings\n",
    "\n",
    "We load the documents from the provided URLs and split them into chunks using the CharacterTextSplitter with a chunk size of 1000 and no overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1212, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 8\n",
      "Documents split: 141\n"
     ]
    }
   ],
   "source": [
    "# use the selenium scraper to load the documents\n",
    "#loader = SeleniumURLLoader(urls=urls)\n",
    "loader = WebBaseLoader(urls)\n",
    "docs_not_splitted = loader.load()\n",
    "\n",
    "print('Documents:', len(docs_not_splitted))\n",
    "\n",
    "# we remove the documents with no text, if using Selenium\n",
    "#docs = [doc for doc in docs_not_splitted if doc.text]\n",
    "\n",
    "# we split the documents into smaller chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs_not_splitted)\n",
    "\n",
    "print('Documents split:', len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the embeddings using OpenAIEmbeddings and store them in a Deep Lake vector store on the cloud. In an ideal production scenario, we could upload a whole website or course lesson on a Deep Lake dataset, allowing for search among even thousands or millions of documents. As we are using a cloud serverless Deep Lake dataset, applications running on different locations can easily access the same centralized dataset without the need of deploying a vector store on a custom machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.0) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/edumunozsala/langchain_course_customer_support\n",
      "hub://edumunozsala/langchain_course_customer_support loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [00:15<00:00\n",
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://edumunozsala/langchain_course_customer_support', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (141, 1536)  float32   None   \n",
      "    ids      text     (141, 1)      str     None   \n",
      " metadata    json     (141, 1)      str     None   \n",
      "   text      text     (141, 1)      str     None   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['d55d3674-6b69-11ee-ab11-cc2f714963ed',\n",
       " 'd55d3675-6b69-11ee-bbcd-cc2f714963ed',\n",
       " 'd55d3676-6b69-11ee-9512-cc2f714963ed',\n",
       " 'd55d3677-6b69-11ee-a5a5-cc2f714963ed',\n",
       " 'd55d3678-6b69-11ee-b59f-cc2f714963ed',\n",
       " 'd55d3679-6b69-11ee-a5d1-cc2f714963ed',\n",
       " 'd55d367a-6b69-11ee-a698-cc2f714963ed',\n",
       " 'd55d367b-6b69-11ee-a576-cc2f714963ed',\n",
       " 'd55d367c-6b69-11ee-a3f3-cc2f714963ed',\n",
       " 'd55d367d-6b69-11ee-a881-cc2f714963ed',\n",
       " 'd55d367e-6b69-11ee-8abb-cc2f714963ed',\n",
       " 'd55d367f-6b69-11ee-84ec-cc2f714963ed',\n",
       " 'd55d3680-6b69-11ee-83fa-cc2f714963ed',\n",
       " 'd55d3681-6b69-11ee-8f73-cc2f714963ed',\n",
       " 'd55d3682-6b69-11ee-a7ee-cc2f714963ed',\n",
       " 'd55d3683-6b69-11ee-913c-cc2f714963ed',\n",
       " 'd55d3684-6b69-11ee-9d43-cc2f714963ed',\n",
       " 'd55d3685-6b69-11ee-a873-cc2f714963ed',\n",
       " 'd55d3686-6b69-11ee-a0a4-cc2f714963ed',\n",
       " 'd55d3687-6b69-11ee-992f-cc2f714963ed',\n",
       " 'd55d3688-6b69-11ee-ab50-cc2f714963ed',\n",
       " 'd55d3689-6b69-11ee-967b-cc2f714963ed',\n",
       " 'd55d368a-6b69-11ee-80c7-cc2f714963ed',\n",
       " 'd55d368b-6b69-11ee-ad95-cc2f714963ed',\n",
       " 'd55d368c-6b69-11ee-bfc8-cc2f714963ed',\n",
       " 'd55d368d-6b69-11ee-bc36-cc2f714963ed',\n",
       " 'd55d368e-6b69-11ee-9966-cc2f714963ed',\n",
       " 'd55d368f-6b69-11ee-b904-cc2f714963ed',\n",
       " 'd55d3690-6b69-11ee-90f6-cc2f714963ed',\n",
       " 'd55d3691-6b69-11ee-84c2-cc2f714963ed',\n",
       " 'd55d3692-6b69-11ee-b141-cc2f714963ed',\n",
       " 'd55d3693-6b69-11ee-aa29-cc2f714963ed',\n",
       " 'd55d3694-6b69-11ee-8b19-cc2f714963ed',\n",
       " 'd55d3695-6b69-11ee-bf4a-cc2f714963ed',\n",
       " 'd55d3696-6b69-11ee-b096-cc2f714963ed',\n",
       " 'd55d3697-6b69-11ee-9fad-cc2f714963ed',\n",
       " 'd55d3698-6b69-11ee-964a-cc2f714963ed',\n",
       " 'd55d3699-6b69-11ee-ac9b-cc2f714963ed',\n",
       " 'd55d369a-6b69-11ee-a690-cc2f714963ed',\n",
       " 'd55d369b-6b69-11ee-8bef-cc2f714963ed',\n",
       " 'd55d369c-6b69-11ee-8663-cc2f714963ed',\n",
       " 'd55d369d-6b69-11ee-9f91-cc2f714963ed',\n",
       " 'd55d369e-6b69-11ee-ac8f-cc2f714963ed',\n",
       " 'd55d369f-6b69-11ee-a374-cc2f714963ed',\n",
       " 'd55d36a0-6b69-11ee-ba10-cc2f714963ed',\n",
       " 'd55d36a1-6b69-11ee-871f-cc2f714963ed',\n",
       " 'd55d36a2-6b69-11ee-ab11-cc2f714963ed',\n",
       " 'd55d36a3-6b69-11ee-ad17-cc2f714963ed',\n",
       " 'd55d36a4-6b69-11ee-988f-cc2f714963ed',\n",
       " 'd55d5d73-6b69-11ee-bb5a-cc2f714963ed',\n",
       " 'd55d5d74-6b69-11ee-91d5-cc2f714963ed',\n",
       " 'd55d5d75-6b69-11ee-a1b8-cc2f714963ed',\n",
       " 'd55d5d76-6b69-11ee-a932-cc2f714963ed',\n",
       " 'd55d5d77-6b69-11ee-a4fb-cc2f714963ed',\n",
       " 'd55d5d78-6b69-11ee-8f44-cc2f714963ed',\n",
       " 'd55d5d79-6b69-11ee-917b-cc2f714963ed',\n",
       " 'd55d5d7a-6b69-11ee-bb32-cc2f714963ed',\n",
       " 'd55d5d7b-6b69-11ee-ae4a-cc2f714963ed',\n",
       " 'd55d5d7c-6b69-11ee-b5f4-cc2f714963ed',\n",
       " 'd55d5d7d-6b69-11ee-b1c0-cc2f714963ed',\n",
       " 'd55d5d7e-6b69-11ee-bedc-cc2f714963ed',\n",
       " 'd55d5d7f-6b69-11ee-a034-cc2f714963ed',\n",
       " 'd55d5d80-6b69-11ee-a861-cc2f714963ed',\n",
       " 'd55d5d81-6b69-11ee-8300-cc2f714963ed',\n",
       " 'd55d5d82-6b69-11ee-8a8a-cc2f714963ed',\n",
       " 'd55d5d83-6b69-11ee-9a59-cc2f714963ed',\n",
       " 'd55d5d84-6b69-11ee-8d4a-cc2f714963ed',\n",
       " 'd55d5d85-6b69-11ee-bfee-cc2f714963ed',\n",
       " 'd55d5d86-6b69-11ee-a61a-cc2f714963ed',\n",
       " 'd55d5d87-6b69-11ee-a2e8-cc2f714963ed',\n",
       " 'd55d5d88-6b69-11ee-9cce-cc2f714963ed',\n",
       " 'd55d5d89-6b69-11ee-ac6f-cc2f714963ed',\n",
       " 'd55d5d8a-6b69-11ee-b1ad-cc2f714963ed',\n",
       " 'd55d5d8b-6b69-11ee-abeb-cc2f714963ed',\n",
       " 'd55d5d8c-6b69-11ee-8a23-cc2f714963ed',\n",
       " 'd55d5d8d-6b69-11ee-9655-cc2f714963ed',\n",
       " 'd55d5d8e-6b69-11ee-b3b0-cc2f714963ed',\n",
       " 'd55d5d8f-6b69-11ee-b13f-cc2f714963ed',\n",
       " 'd55d5d90-6b69-11ee-bce1-cc2f714963ed',\n",
       " 'd55d5d91-6b69-11ee-bf68-cc2f714963ed',\n",
       " 'd55d5d92-6b69-11ee-aa48-cc2f714963ed',\n",
       " 'd55d5d93-6b69-11ee-8382-cc2f714963ed',\n",
       " 'd55d5d94-6b69-11ee-b72d-cc2f714963ed',\n",
       " 'd55d5d95-6b69-11ee-b1fe-cc2f714963ed',\n",
       " 'd55d5d96-6b69-11ee-9116-cc2f714963ed',\n",
       " 'd55d5d97-6b69-11ee-9951-cc2f714963ed',\n",
       " 'd55d5d98-6b69-11ee-bd30-cc2f714963ed',\n",
       " 'd55d5d99-6b69-11ee-8730-cc2f714963ed',\n",
       " 'd55d5d9a-6b69-11ee-916c-cc2f714963ed',\n",
       " 'd55d5d9b-6b69-11ee-9711-cc2f714963ed',\n",
       " 'd55d5d9c-6b69-11ee-8208-cc2f714963ed',\n",
       " 'd55d5d9d-6b69-11ee-a210-cc2f714963ed',\n",
       " 'd55d5d9e-6b69-11ee-a25a-cc2f714963ed',\n",
       " 'd55d5d9f-6b69-11ee-aee6-cc2f714963ed',\n",
       " 'd55d5da0-6b69-11ee-99d9-cc2f714963ed',\n",
       " 'd55d5da1-6b69-11ee-bc5f-cc2f714963ed',\n",
       " 'd55d5da2-6b69-11ee-875a-cc2f714963ed',\n",
       " 'd55d5da3-6b69-11ee-93d1-cc2f714963ed',\n",
       " 'd55d5da4-6b69-11ee-9b73-cc2f714963ed',\n",
       " 'd55d5da5-6b69-11ee-9849-cc2f714963ed',\n",
       " 'd55d5da6-6b69-11ee-b778-cc2f714963ed',\n",
       " 'd55d5da7-6b69-11ee-8558-cc2f714963ed',\n",
       " 'd55d5da8-6b69-11ee-beec-cc2f714963ed',\n",
       " 'd55d5da9-6b69-11ee-b46f-cc2f714963ed',\n",
       " 'd55d5daa-6b69-11ee-8cfe-cc2f714963ed',\n",
       " 'd55d5dab-6b69-11ee-af4e-cc2f714963ed',\n",
       " 'd55d5dac-6b69-11ee-a641-cc2f714963ed',\n",
       " 'd55d8490-6b69-11ee-9b06-cc2f714963ed',\n",
       " 'd55d8491-6b69-11ee-a0c1-cc2f714963ed',\n",
       " 'd55d8492-6b69-11ee-b00c-cc2f714963ed',\n",
       " 'd55d8493-6b69-11ee-a297-cc2f714963ed',\n",
       " 'd55d8494-6b69-11ee-91a3-cc2f714963ed',\n",
       " 'd55d8495-6b69-11ee-9c75-cc2f714963ed',\n",
       " 'd55d8496-6b69-11ee-b1c2-cc2f714963ed',\n",
       " 'd55d8497-6b69-11ee-8f57-cc2f714963ed',\n",
       " 'd55d8498-6b69-11ee-a6c2-cc2f714963ed',\n",
       " 'd55d8499-6b69-11ee-b736-cc2f714963ed',\n",
       " 'd55d849a-6b69-11ee-a206-cc2f714963ed',\n",
       " 'd55d849b-6b69-11ee-9979-cc2f714963ed',\n",
       " 'd55d849c-6b69-11ee-971c-cc2f714963ed',\n",
       " 'd55d849d-6b69-11ee-9244-cc2f714963ed',\n",
       " 'd55d849e-6b69-11ee-beeb-cc2f714963ed',\n",
       " 'd55d849f-6b69-11ee-8fb4-cc2f714963ed',\n",
       " 'd55d84a0-6b69-11ee-bf67-cc2f714963ed',\n",
       " 'd55d84a1-6b69-11ee-a44b-cc2f714963ed',\n",
       " 'd55d84a2-6b69-11ee-8b4a-cc2f714963ed',\n",
       " 'd55dac85-6b69-11ee-9527-cc2f714963ed',\n",
       " 'd55dac86-6b69-11ee-9170-cc2f714963ed',\n",
       " 'd55dac87-6b69-11ee-8d20-cc2f714963ed',\n",
       " 'd55dac88-6b69-11ee-b868-cc2f714963ed',\n",
       " 'd55dac89-6b69-11ee-8cb1-cc2f714963ed',\n",
       " 'd55dac8a-6b69-11ee-af25-cc2f714963ed',\n",
       " 'd55dac8b-6b69-11ee-b4cc-cc2f714963ed',\n",
       " 'd55dac8c-6b69-11ee-ba6c-cc2f714963ed',\n",
       " 'd55dac8d-6b69-11ee-bf5f-cc2f714963ed',\n",
       " 'd55dac8e-6b69-11ee-a85c-cc2f714963ed',\n",
       " 'd55dac8f-6b69-11ee-9e36-cc2f714963ed',\n",
       " 'd55dac90-6b69-11ee-ae3c-cc2f714963ed',\n",
       " 'd55dac91-6b69-11ee-a803-cc2f714963ed',\n",
       " 'd55dac92-6b69-11ee-b8ec-cc2f714963ed',\n",
       " 'd55dac93-6b69-11ee-b8de-cc2f714963ed']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create Deep Lake dataset\n",
    "my_activeloop_org_id = \"edumunozsala\"\n",
    "my_activeloop_dataset_name = \"langchain_course_customer_support\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the most similar chunks to a given query, we can use the similarity_search method of the Deep Lake vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Disk Usage Using Gnome Disk ToolCheck Disk Usage Using Disk Usage Analyzer ToolCleanup Disk using Disk Usage Analyzer\n",
      "\n",
      "\n",
      "Check Disk Space Using the df Command\n",
      "In Linux, there are many commands to check disk usage, the most common being the df command. The df stands for “Disk Filesystem” in the command, which is a handy way to check the current disk usage and the available disk space in Linux. The syntax for the df command in Linux is as follows:\n",
      "\n",
      "\n",
      "\n",
      "df <options> <file_system>\n",
      "The options to use with the df command are:\n"
     ]
    }
   ],
   "source": [
    "# let's see the top relevant documents to a specific query\n",
    "query = \"how to check disk usage in linux?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print the content of the first document\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Craft a prompt for GPT-3 using the suggested strategies\n",
    "\n",
    "We will create a prompt template that incorporates role-prompting, relevant Knowledge Base information, and the user's question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's write a prompt for a customer support chatbot that\n",
    "# answer questions using information extracted from our db\n",
    "template = \"\"\"You are an exceptional customer support chatbot that gently answer questions.\n",
    "\n",
    "You know the following context information.\n",
    "\n",
    "{chunks_formatted}\n",
    "\n",
    "Answer to the following question from a customer. Use only information from the previous context information. Do not invent stuff.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chunks_formatted\", \"query\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Utilize the GPT3 model with a temperature of 0 for text generation\n",
    "\n",
    "To generate a response, we first retrieve the top-k (e.g., top-3) chunks most similar to the user query, format the prompt, and send the formatted prompt to the GPT3 model with a temperature of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can check disk usage in Linux using the df command. This command stands for “Disk Filesystem” and is a handy way to check the current disk usage and the available disk space in Linux. The syntax for the df command in Linux is as follows: df <options> <file_system>. Additionally, you can also use the du command to check disk usage in Linux. This command stands for “Disk Usage” and is used to display disk occupancy of a particular type or disk usage for a particular directory. You can also use a GUI application such as Gnome Disk Tool or Disk Usage Analyzer to check disk usage in Linux.\n"
     ]
    }
   ],
   "source": [
    "# the full pipeline\n",
    "\n",
    "# user question\n",
    "query = \"How to check disk usage in linux?\"\n",
    "\n",
    "# retrieve relevant chunks\n",
    "docs = db.similarity_search(query)\n",
    "retrieved_chunks = [doc.page_content for doc in docs]\n",
    "\n",
    "# format the prompt\n",
    "chunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n",
    "prompt_formatted = prompt.format(chunks_formatted=chunks_formatted, query=query)\n",
    "\n",
    "# generate answer\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "answer = llm(prompt_formatted)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
