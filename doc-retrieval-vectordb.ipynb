{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Custom Document Retrieval Tool with Deep Lake and LangChain: A Step-by-Step Workflow\n",
    "## Introduction\n",
    "\n",
    "This lesson is a walkthrough on constructing an efficient document retrieval system designed to extract valuable insights from the FAQs of a service. The goal of this system is to swiftly provide users with relevant information by promptly fetching pertinent documents that explain a company's operations.\n",
    "\n",
    "Sifting through multiple sources or FAQs can be a tiresome task for users. Our retrieval system steps in here, providing concise, precise, and quick answers to these questions, thereby saving users time and effort.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Setting up Deep Lake:  Deep Lake is a type of vector store database designed for storing and querying high-dimensional vectors efficiently. In our case, we're using Deep Lake to store document embeddings and their corresponding text.\n",
    "2. Storing documents in Deep Lake: Once Deep Lake is set up, we’ll create embeddings for our documents. In this workflow, we're using OpenAI's model for creating these embeddings. Each document's text is fed into the model, and the output is a high-dimensional vector representing the text's semantic content. The embeddings and their corresponding documents are then stored in Deep Lake. This will set up our vector database, which is ready to be queried.\n",
    "3. Creating the retrieval tool: Now, we use Langchain to create a custom tool that will interact with Deep Lake. This tool is essentially a function that takes a query as input and returns the most similar documents from Deep Lake as output. \n",
    "4. To find the most similar documents, the tool first computes the embedding of the query using the same model we used for the documents. Then, it queries Deep Lake with this query embedding, and Deep Lake returns the documents whose embeddings are most similar to the query embedding.\n",
    "5. Using the tool with an agent: Finally, we use this custom tool with an agent from Langchain. When the agent receives a question, it uses the tool to retrieve relevant documents from Deep Lake, and then it uses its language model to generate a response based on these documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Deep Lake\n",
    "\n",
    "Next, we'll set up a Deep Lake vector database and add some documents to it. The hub path for a Deep Lake dataset is in the format hub://<org_id>/<dataset_name>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n",
      "c:\\Users\\edumu\\anaconda3\\envs\\llm-lc\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.3) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/edumunozsala/langchain_course_custom_tool\n",
      "hub://edumunozsala/langchain_course_custom_tool loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# We'll use an embedding model to compute the embeddings of our documents\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# instantiate embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# We'll store the documents and their embeddings in the deep lake vector db\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"edumunozsala\"\n",
    "my_activeloop_dataset_name = \"langchain_course_custom_tool\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing documents in Deep Lake\n",
    "\n",
    "We can then add some FAQs related to PayPal as our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [00:15<00:00\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://edumunozsala/langchain_course_custom_tool', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (5, 1536)  float32   None   \n",
      "    ids      text     (5, 1)      str     None   \n",
      " metadata    json     (5, 1)      str     None   \n",
      "   text      text     (5, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# add faqs to the dataset\n",
    "faqs = [\n",
    "    \"What is PayPal?\\nPayPal is a digital wallet that follows you wherever you go. Pay any way you want. Link your credit cards to your PayPal Digital wallet, and when you want to pay, simply log in with your username and password and pick which one you want to use.\",\n",
    "    \"Why should I use PayPal?\\nIt's Fast! We will help you pay in just a few clicks. Enter your email address and password, and you're pretty much done! It's Simple! There's no need to run around searching for your wallet. Better yet, you don't need to type in your financial details again and again when making a purchase online. We make it simple for you to pay with just your email address and password.\",\n",
    "    \"Is it secure?\\nPayPal is the safer way to pay because we keep your financial information private. It isn't shared with anyone else when you shop, so you don't have to worry about paying businesses and people you don't know. On top of that, we've got your back. If your eligible purchase doesn't arrive or doesn't match its description, we will refund you the full purchase price plus shipping costs with PayPal's Buyer Protection program.\",\n",
    "    \"Where can I use PayPal?\\nThere are millions of places you can use PayPal worldwide. In addition to online stores, there are many charities that use PayPal to raise money. Find a list of charities you can donate to here. Additionally, you can send funds internationally to anyone almost anywhere in the world with PayPal. All you need is their email address. Sending payments abroad has never been easier.\",\n",
    "    \"Do I need a balance in my account to use it?\\nYou do not need to have any balance in your account to use PayPal. Similar to a physical wallet, when you are making a purchase, you can choose to pay for your items with any of the credit cards that are attached to your account. There is no need to pre-fund your account.\"\n",
    "]\n",
    "db.add_texts(faqs)\n",
    "\n",
    "# Get the retriever object from the deep lake db object\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the retrieval tool\n",
    "\n",
    "Now, we’ll construct the custom tool function that will retrieve the relevant documents from the Deep Lake database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# We define some variables that will be used inside our custom tool\n",
    "# We're creating a custom tool that looks for relevant documents in our deep lake db\n",
    "CUSTOM_TOOL_N_DOCS = 3 # number of retrieved docs from deep lake to consider\n",
    "CUSTOM_TOOL_DOCS_SEPARATOR =\"\\n\\n\" # how to join together the retrieved docs to form a single string\n",
    "\n",
    "# We use the tool decorator to wrap a function that will become our custom tool\n",
    "# Note that the tool has a single string as input and returns a single string as output\n",
    "# The name of the function will be the name of our custom tool\n",
    "# The docstring of the function will be the description of our custom tool\n",
    "# The description is used by the agent to decide whether to use the tool for a specific query\n",
    "@tool\n",
    "def retrieve_n_docs_tool(query: str) -> str:\n",
    "    \"\"\" Searches for relevant documents that may contain the answer to the query.\"\"\"\n",
    "    docs = retriever.get_relevant_documents(query)[:CUSTOM_TOOL_N_DOCS]\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    texts_merged = CUSTOM_TOOL_DOCS_SEPARATOR.join(texts)\n",
    "    return texts_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function, retrieve_n_docs_tool, is designed with a specific purpose in mind - to search for and retrieve relevant documents based on a given query. It accepts a single string input, which is the user's question or query, and it's designed to return a single string output.\n",
    "\n",
    "To find the relevant documents, our function makes use of the retriever object's get_relevant_documents method. Given the query, this method searches for and returns a list of the most relevant documents. But we only need some of the documents it finds. We only want the top few. That's where the [: CUSTOM_TOOL_N_DOCS] slice comes in. It allows us to select the top CUSTOM_TOOL_N_DOCS number of documents from the list, where CUSTOM_TOOL_N_DOCS is a predefined constant that tells us how many documents to consider. In this case, that’s 3 documents, as we specified. \n",
    "\n",
    "Now that we have our top documents, we want to extract the text from each of them. We achieve this using a list comprehension that iterates over each document in our list, docs, and extracts the page_content or text from each document. The result is a list of the top 3 relevant document texts. Next, we want to join these individual texts from a list into a single string using .join(texts) method. Finally, our function returns texts_merged, a single string that comprises the joined texts from the relevant documents. The @tool decorator wraps the function, turning it into a custom tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the tool with an agent\n",
    "\n",
    "We can now initialize the agent that uses our custom tool.\n",
    "\n",
    "The initialize_agent function takes in three parameters: a list of the custom tools, the language learning model, and the type of agent. We're using the OpenAI LLM and specifying the agent type as ZERO_SHOT_REACT_DESCRIPTION. With verbose=True we can check if the agent is using the tool when generating the final answer.\n",
    "\n",
    "Once the agent has been set up, it can be queried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what Paypal does to protect my information\n",
      "Action: retrieve_n_docs_tool\n",
      "Action Input: \"Paypal privacy policy\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIs it secure?\n",
      "PayPal is the safer way to pay because we keep your financial information private. It isn't shared with anyone else when you shop, so you don't have to worry about paying businesses and people you don't know. On top of that, we've got your back. If your eligible purchase doesn't arrive or doesn't match its description, we will refund you the full purchase price plus shipping costs with PayPal's Buyer Protection program.\n",
      "\n",
      "Why should I use PayPal?\n",
      "It's Fast! We will help you pay in just a few clicks. Enter your email address and password, and you're pretty much done! It's Simple! There's no need to run around searching for your wallet. Better yet, you don't need to type in your financial details again and again when making a purchase online. We make it simple for you to pay with just your email address and password.\n",
      "\n",
      "What is PayPal?\n",
      "PayPal is a digital wallet that follows you wherever you go. Pay any way you want. Link your credit cards to your PayPal Digital wallet, and when you want to pay, simply log in with your username and password and pick which one you want to use.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now understand how Paypal keeps my information secure\n",
      "Final Answer: Yes, your information is kept private when you shop with Paypal. PayPal is a digital wallet that follows you wherever you go and keeps your financial information private. It is not shared with anyone else when you shop, and PayPal also offers Buyer Protection to refund you the full purchase price plus shipping costs if your eligible purchase doesn't arrive or doesn't match its description.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Yes, your information is kept private when you shop with Paypal. PayPal is a digital wallet that follows you wherever you go and keeps your financial information private. It is not shared with anyone else when you shop, and PayPal also offers Buyer Protection to refund you the full purchase price plus shipping costs if your eligible purchase doesn't arrive or doesn't match its description.\n"
     ]
    }
   ],
   "source": [
    "# Load a LLM to create an agent using our custom tool\n",
    "from langchain.llms import OpenAI\n",
    "# Classes for initializing the agent that will use the custom tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Let's create an agent that uses our custom tool\n",
    "# We set verbose=True to check if the agent is using the tool for generating the final answer\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "agent = initialize_agent([retrieve_n_docs_tool], llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "# Get the response\n",
    "response = agent.run(\"Are my info kept private when I shop with Paypal?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tool.__init__() missing 1 required positional argument: 'func'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edumu\\Google Drive\\Github\\langchain-vectordb-basics\\doc-retrieval-vectordb.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m Tool\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tool \u001b[39m=\u001b[39m Tool(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mGoogle Search\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSearch Google for recent results.\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Tool.__init__() missing 1 required positional argument: 'func'"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GoogleSearchAPIWrapper' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edumu\\Google Drive\\Github\\langchain-vectordb-basics\\doc-retrieval-vectordb.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m GoogleSearchAPIWrapper\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m search \u001b[39m=\u001b[39m GoogleSearchAPIWrapper()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tool \u001b[39m=\u001b[39m Tool(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGoogle Search\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSearch Google for recent results.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     func\u001b[39m=\u001b[39msearch\u001b[39m.\u001b[39;49mexecute\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/edumu/Google%20Drive/Github/langchain-vectordb-basics/doc-retrieval-vectordb.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GoogleSearchAPIWrapper' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=search.execute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
