{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 and ChatGPT\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, we will explore the benefits of using GPT-4 and ChatGPT, focusing on their ability to maintain context in conversations. We will demonstrate how these advanced language models can remember conversation history and respond accordingly, making them ideal for chat applications. Additionally, we will briefly discuss the improvements in GPT-4, such as longer context length and better generalization. By the end of this lesson, you should be able to understand how GPT-4 and ChatGPT can be used for context-aware chat applications via the API, as opposed to just using the OpenAI ChatGPT webpage. \n",
    "\n",
    "As mentioned before, OpenAI's GPT-4 represents a significant advancement in the field of large language models. Among its many improvements are enhanced creativity, the ability to process visual input, and an extended contextual understanding. In the realm of conversational AI, both GPT-4 and ChatGPT use the Transformers architecture at their core and are fine-tuned to hold natural dialogue with a user. While the free version of ChatGPT relies on GPT-3, the premium offering, ChatGPT Plus, gives access to the more advanced GPT-4 model.\n",
    "\n",
    "The benefits of employing ChatGPT and GPT-4 in chat format are numerous. For instance, GPT-4's short-term memory capacity of 64,000 words greatly surpasses GPT-3.5's 8,000-word limit, enabling it to maintain context more effectively in prolonged conversations. Furthermore, GPT-4 is highly multilingual, accurately handling up to 26 languages, and boasts improved steering capabilities, allowing users to tailor responses with a custom \"personality.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Read the enviroment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the user posed the question about the capital of France, the model confidently answered with \"Paris.” Next up, we test if the model can leverage these discussions as a reference to delve further into details about the city without us explicitly mentioning the name (referring to Paris). The code below adds a new message which requires the model to understand and find the “city you just mentioned” reference from previous conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT4 as model name\n",
    "#model_name=\"gpt-4\"\n",
    "# If not acccess to GPT-4, use 3.5\n",
    "model_name=\"gpt-3.5-turbo-16k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"I'd like to know more about the city you just mentioned.\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "llm = ChatOpenAI(model_name=model_name)\n",
    "\n",
    "response = llm(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To recap, the ChatOpenAI class is used to create a chat-based application that can handle user inputs and generate responses using the GPT-4 language model. The conversation is initiated with a series of messages, including system, human, and AI messages. The SystemMessage provides context for the conversation, while HumanMessage and AIMessage represent the user and the AI's messages, respectively.\n",
    "\n",
    "The LangChain’s Chat API offers several advantages:\n",
    "\n",
    "- Context preservation: By maintaining a list of messages in the conversation, the API ensures that the context is preserved throughout the interaction. This allows the GPT-4 model to generate relevant and coherent responses based on the provided information.\n",
    "- Memory: The class’s message history acts as a short-term memory for the chatbot, allowing it to refer back to previous messages and provide more accurate and contextual responses.\n",
    "- Modularity: The combination of MessageTemplate and ChatOpenAI classes offers a modular approach to designing conversation applications. This makes it easier to develop, maintain, and extend the functionality of the chatbot.\n",
    "- Improved performance: GPT-4, as an advanced language model, is more adept at understanding complex prompts and generating better responses than its predecessors. It can handle tasks that require deeper reasoning and context awareness, which leads to a more engaging and useful conversation experience.\n",
    "- Flexibility: The Chat API can be adapted to different domains and tasks, making it a versatile solution for various chatbot applications. In this example, the chatbot specializes in French culture but could be easily modified to focus on other subjects or industries. Moreover, as newer and more powerful language models become available, the API can be updated to utilize those models, allowing for continuous improvements in chatbot capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
